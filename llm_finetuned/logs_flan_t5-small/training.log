2024-09-02 21:30:00,402 - INFO - Number of training examples: 443499 
 Number of validation examples: 95035
2024-09-02 21:30:00,475 - INFO - Training Arguments: TrainingArguments(
_n_gpu=2,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=epoch,
eval_use_gather_object=False,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.002,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./logs_flan_t5-small,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=200,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=60,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=./results_flan_t5-small,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=96,
per_device_train_batch_size=96,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=./results_flan_t5-small,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=3,
seed=42,
skip_memory_metrics=True,
split_batches=None,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.01,
)
2024-09-02 21:32:36,432 - INFO - Step: 200
loss: 0.4894
grad_norm: 0.08129601180553436
learning_rate: 0.0019971139971139973
epoch: 0.08658008658008658


2024-09-02 21:35:15,161 - INFO - Step: 400
loss: 0.0393
grad_norm: 0.05434322729706764
learning_rate: 0.001994227994227994
epoch: 0.17316017316017315


2024-09-02 21:37:54,489 - INFO - Step: 600
loss: 0.0253
grad_norm: 0.05401860550045967
learning_rate: 0.0019913419913419913
epoch: 0.2597402597402597


2024-09-02 21:40:33,313 - INFO - Step: 800
loss: 0.0192
grad_norm: 0.040989287197589874
learning_rate: 0.0019884559884559886
epoch: 0.3463203463203463


2024-09-02 21:43:12,262 - INFO - Step: 1000
loss: 0.0155
grad_norm: 0.0487683080136776
learning_rate: 0.0019855699855699854
epoch: 0.4329004329004329


2024-09-02 21:45:52,172 - INFO - Step: 1200
loss: 0.0131
grad_norm: 0.03312196582555771
learning_rate: 0.0019826839826839826
epoch: 0.5194805194805194


2024-09-02 21:48:30,973 - INFO - Step: 1400
loss: 0.0113
grad_norm: 0.03150150924921036
learning_rate: 0.00197979797979798
epoch: 0.6060606060606061


2024-09-02 21:51:10,922 - INFO - Step: 1600
loss: 0.01
grad_norm: 0.04739311710000038
learning_rate: 0.001976911976911977
epoch: 0.6926406926406926


2024-09-02 21:53:49,986 - INFO - Step: 1800
loss: 0.0088
grad_norm: 0.03142888471484184
learning_rate: 0.001974025974025974
epoch: 0.7792207792207793


2024-09-02 21:56:28,908 - INFO - Step: 2000
loss: 0.0081
grad_norm: 0.028735855594277382
learning_rate: 0.001971139971139971
epoch: 0.8658008658008658


2024-09-02 21:59:09,342 - INFO - Step: 2200
loss: 0.0075
grad_norm: 0.036344923079013824
learning_rate: 0.001968253968253968
epoch: 0.9523809523809523


2024-09-02 22:03:48,259 - INFO - Step: 2310
eval_loss: 0.00392407039180398
eval_runtime: 191.186
eval_samples_per_second: 497.081
eval_steps_per_second: 2.589
epoch: 1.0


2024-09-02 22:04:59,572 - INFO - Step: 2400
loss: 0.0068
grad_norm: 0.034768931567668915
learning_rate: 0.0019653679653679657
epoch: 1.0389610389610389


2024-09-02 22:07:40,085 - INFO - Step: 2600
loss: 0.0062
grad_norm: 0.027157006785273552
learning_rate: 0.0019624819624819625
epoch: 1.1255411255411256


2024-09-02 22:10:19,169 - INFO - Step: 2800
loss: 0.0061
grad_norm: 0.02342909760773182
learning_rate: 0.0019595959595959597
epoch: 1.2121212121212122


2024-09-02 22:12:58,174 - INFO - Step: 3000
loss: 0.006
grad_norm: 0.021535053849220276
learning_rate: 0.0019567099567099565
epoch: 1.2987012987012987


2024-09-02 22:15:38,413 - INFO - Step: 3200
loss: 0.0057
grad_norm: 0.021609077230095863
learning_rate: 0.0019538239538239538
epoch: 1.3852813852813852


2024-09-02 22:18:17,199 - INFO - Step: 3400
loss: 0.0055
grad_norm: 0.020191263407468796
learning_rate: 0.001950937950937951
epoch: 1.4718614718614718


2024-09-02 22:20:57,709 - INFO - Step: 3600
loss: 0.0053
grad_norm: 0.023057440295815468
learning_rate: 0.001948051948051948
epoch: 1.5584415584415585


2024-09-02 22:23:37,272 - INFO - Step: 3800
loss: 0.0052
grad_norm: 0.02436310052871704
learning_rate: 0.001945165945165945
epoch: 1.645021645021645


2024-09-02 22:26:16,508 - INFO - Step: 4000
loss: 0.0048
grad_norm: 0.020597251132130623
learning_rate: 0.0019422799422799423
epoch: 1.7316017316017316


2024-09-02 22:28:56,894 - INFO - Step: 4200
loss: 0.005
grad_norm: 0.026361173018813133
learning_rate: 0.0019393939393939396
epoch: 1.8181818181818183


2024-09-02 22:31:35,707 - INFO - Step: 4400
loss: 0.0046
grad_norm: 0.02058151364326477
learning_rate: 0.0019365079365079366
epoch: 1.9047619047619047


2024-09-02 22:34:15,971 - INFO - Step: 4600
loss: 0.0047
grad_norm: 0.026833539828658104
learning_rate: 0.0019336219336219336
epoch: 1.9913419913419914


2024-09-02 22:37:43,137 - INFO - Step: 4620
eval_loss: 0.0028866552747786045
eval_runtime: 191.3853
eval_samples_per_second: 496.564
eval_steps_per_second: 2.586
epoch: 2.0


2024-09-02 22:40:06,480 - INFO - Step: 4800
loss: 0.0043
grad_norm: 0.019163481891155243
learning_rate: 0.0019307359307359306
epoch: 2.0779220779220777


2024-09-02 22:42:45,912 - INFO - Step: 5000
loss: 0.0042
grad_norm: 0.01978970877826214
learning_rate: 0.001927849927849928
epoch: 2.1645021645021645


2024-09-02 22:45:26,257 - INFO - Step: 5200
loss: 0.0041
grad_norm: 0.027941040694713593
learning_rate: 0.0019249639249639251
epoch: 2.2510822510822512


2024-09-02 22:48:05,689 - INFO - Step: 5400
loss: 0.0039
grad_norm: 0.015476083382964134
learning_rate: 0.0019220779220779222
epoch: 2.3376623376623376


2024-09-02 22:50:46,538 - INFO - Step: 5600
loss: 0.004
grad_norm: 0.027779091149568558
learning_rate: 0.0019191919191919192
epoch: 2.4242424242424243


2024-09-02 22:53:26,070 - INFO - Step: 5800
loss: 0.0038
grad_norm: 0.020587459206581116
learning_rate: 0.0019163059163059164
epoch: 2.5108225108225106


2024-09-02 22:56:05,749 - INFO - Step: 6000
loss: 0.0038
grad_norm: 0.018992416560649872
learning_rate: 0.0019134199134199135
epoch: 2.5974025974025974


2024-09-02 22:58:46,385 - INFO - Step: 6200
loss: 0.0037
grad_norm: 0.02339514158666134
learning_rate: 0.0019105339105339105
epoch: 2.683982683982684


2024-09-02 23:01:25,777 - INFO - Step: 6400
loss: 0.0037
grad_norm: 0.025005843490362167
learning_rate: 0.0019076479076479077
epoch: 2.7705627705627704


2024-09-02 23:04:06,100 - INFO - Step: 6600
loss: 0.0038
grad_norm: 0.01760854758322239
learning_rate: 0.0019047619047619048
epoch: 2.857142857142857


2024-09-02 23:06:45,172 - INFO - Step: 6800
loss: 0.0037
grad_norm: 0.027988119050860405
learning_rate: 0.001901875901875902
epoch: 2.9437229437229435


2024-09-02 23:11:39,892 - INFO - Step: 6930
eval_loss: 0.002563286107033491
eval_runtime: 191.3318
eval_samples_per_second: 496.703
eval_steps_per_second: 2.587
epoch: 3.0


2024-09-02 23:12:35,382 - INFO - Step: 7000
loss: 0.0035
grad_norm: 0.021604392677545547
learning_rate: 0.001898989898989899
epoch: 3.0303030303030303


2024-09-02 23:15:16,312 - INFO - Step: 7200
loss: 0.0033
grad_norm: 0.017396938055753708
learning_rate: 0.001896103896103896
epoch: 3.116883116883117


2024-09-02 23:17:56,210 - INFO - Step: 7400
loss: 0.0033
grad_norm: 0.01759551279246807
learning_rate: 0.001893217893217893
epoch: 3.2034632034632033


2024-09-02 23:20:36,951 - INFO - Step: 7600
loss: 0.0032
grad_norm: 0.024591749534010887
learning_rate: 0.0018903318903318905
epoch: 3.29004329004329


2024-09-02 23:23:16,570 - INFO - Step: 7800
loss: 0.0032
grad_norm: 0.02048184908926487
learning_rate: 0.0018874458874458876
epoch: 3.3766233766233764


2024-09-02 23:25:56,368 - INFO - Step: 8000
loss: 0.0034
grad_norm: 0.014523942023515701
learning_rate: 0.0018845598845598846
epoch: 3.463203463203463


2024-09-02 23:28:36,767 - INFO - Step: 8200
loss: 0.0034
grad_norm: 0.020272698253393173
learning_rate: 0.0018816738816738816
epoch: 3.54978354978355


2024-09-02 23:31:16,083 - INFO - Step: 8400
loss: 0.0032
grad_norm: 0.01810983568429947
learning_rate: 0.0018787878787878789
epoch: 3.6363636363636362


2024-09-02 23:33:56,672 - INFO - Step: 8600
loss: 0.0031
grad_norm: 0.014437870122492313
learning_rate: 0.001875901875901876
epoch: 3.722943722943723


2024-09-02 23:36:36,253 - INFO - Step: 8800
loss: 0.0032
grad_norm: 0.011889097280800343
learning_rate: 0.0018730158730158731
epoch: 3.8095238095238093


2024-09-02 23:39:15,890 - INFO - Step: 9000
loss: 0.0031
grad_norm: 0.028756078332662582
learning_rate: 0.0018701298701298702
epoch: 3.896103896103896


2024-09-02 23:41:56,761 - INFO - Step: 9200
loss: 0.0032
grad_norm: 0.015784036368131638
learning_rate: 0.0018672438672438672
epoch: 3.982683982683983


2024-09-02 23:45:39,581 - INFO - Step: 9240
eval_loss: 0.0024081796873360872
eval_runtime: 191.0938
eval_samples_per_second: 497.321
eval_steps_per_second: 2.59
epoch: 4.0


2024-09-02 23:47:47,019 - INFO - Step: 9400
loss: 0.0028
grad_norm: 0.014534766785800457
learning_rate: 0.0018643578643578644
epoch: 4.06926406926407


2024-09-02 23:50:27,637 - INFO - Step: 9600
loss: 0.0027
grad_norm: 0.01706457883119583
learning_rate: 0.0018614718614718615
epoch: 4.1558441558441555


2024-09-02 23:53:07,713 - INFO - Step: 9800
loss: 0.0028
grad_norm: 0.013223621994256973
learning_rate: 0.0018585858585858585
epoch: 4.242424242424242


2024-09-02 23:55:47,158 - INFO - Step: 10000
loss: 0.0028
grad_norm: 0.017718086019158363
learning_rate: 0.0018556998556998557
epoch: 4.329004329004329


2024-09-02 23:58:27,767 - INFO - Step: 10200
loss: 0.0029
grad_norm: 0.01812497153878212
learning_rate: 0.001852813852813853
epoch: 4.415584415584416


2024-09-03 00:01:07,755 - INFO - Step: 10400
loss: 0.0028
grad_norm: 0.014370824210345745
learning_rate: 0.00184992784992785
epoch: 4.5021645021645025


2024-09-03 00:03:48,727 - INFO - Step: 10600
loss: 0.0027
grad_norm: 0.013460004702210426
learning_rate: 0.001847041847041847
epoch: 4.588744588744589


2024-09-03 00:06:28,811 - INFO - Step: 10800
loss: 0.0027
grad_norm: 0.017084574326872826
learning_rate: 0.001844155844155844
epoch: 4.675324675324675


2024-09-03 00:09:08,445 - INFO - Step: 11000
loss: 0.0027
grad_norm: 0.013661535456776619
learning_rate: 0.0018412698412698413
epoch: 4.761904761904762


2024-09-03 00:11:49,267 - INFO - Step: 11200
loss: 0.0028
grad_norm: 0.030235368758440018
learning_rate: 0.0018383838383838386
epoch: 4.848484848484849


2024-09-03 00:14:29,239 - INFO - Step: 11400
loss: 0.0028
grad_norm: 0.01739753782749176
learning_rate: 0.0018354978354978356
epoch: 4.935064935064935


2024-09-03 00:19:41,931 - INFO - Step: 11550
eval_loss: 0.0022158073261380196
eval_runtime: 191.6109
eval_samples_per_second: 495.979
eval_steps_per_second: 2.583
epoch: 5.0


2024-09-03 00:20:21,328 - INFO - Step: 11600
loss: 0.0026
grad_norm: 0.012931051664054394
learning_rate: 0.0018326118326118326
epoch: 5.021645021645021


2024-09-03 00:23:00,696 - INFO - Step: 11800
loss: 0.0023
grad_norm: 0.010188866406679153
learning_rate: 0.0018297258297258296
epoch: 5.108225108225108


2024-09-03 00:25:40,724 - INFO - Step: 12000
loss: 0.0026
grad_norm: 0.0077698808163404465
learning_rate: 0.0018268398268398269
epoch: 5.194805194805195


2024-09-03 00:28:21,919 - INFO - Step: 12200
loss: 0.0025
grad_norm: 0.014435548335313797
learning_rate: 0.0018239538239538241
epoch: 5.2813852813852815


2024-09-03 00:31:01,983 - INFO - Step: 12400
loss: 0.0026
grad_norm: 0.011149541474878788
learning_rate: 0.0018210678210678212
epoch: 5.367965367965368


2024-09-03 00:33:43,236 - INFO - Step: 12600
loss: 0.0025
grad_norm: 0.011229577474296093
learning_rate: 0.0018181818181818182
epoch: 5.454545454545454


2024-09-03 00:36:23,095 - INFO - Step: 12800
loss: 0.0025
grad_norm: 0.01229345053434372
learning_rate: 0.0018152958152958152
epoch: 5.541125541125541


2024-09-03 00:39:02,908 - INFO - Step: 13000
loss: 0.0024
grad_norm: 0.012597216293215752
learning_rate: 0.0018124098124098125
epoch: 5.627705627705628


2024-09-03 00:41:44,121 - INFO - Step: 13200
loss: 0.0024
grad_norm: 0.014956523664295673
learning_rate: 0.0018095238095238095
epoch: 5.714285714285714


2024-09-03 00:44:24,430 - INFO - Step: 13400
loss: 0.0025
grad_norm: 0.019687343388795853
learning_rate: 0.0018066378066378067
epoch: 5.800865800865801


2024-09-03 00:47:05,156 - INFO - Step: 13600
loss: 0.0024
grad_norm: 0.008068601600825787
learning_rate: 0.0018037518037518038
epoch: 5.887445887445887


2024-09-03 00:49:45,079 - INFO - Step: 13800
loss: 0.0025
grad_norm: 0.010676237754523754
learning_rate: 0.001800865800865801
epoch: 5.974025974025974


2024-09-03 00:53:45,047 - INFO - Step: 13860
eval_loss: 0.0021563945338129997
eval_runtime: 192.0348
eval_samples_per_second: 494.884
eval_steps_per_second: 2.578
epoch: 6.0


2024-09-03 00:55:36,436 - INFO - Step: 14000
loss: 0.0022
grad_norm: 0.012115885503590107
learning_rate: 0.001797979797979798
epoch: 6.0606060606060606


2024-09-03 00:58:17,506 - INFO - Step: 14200
loss: 0.0022
grad_norm: 0.010212883353233337
learning_rate: 0.001795093795093795
epoch: 6.147186147186147


2024-09-03 01:00:57,491 - INFO - Step: 14400
loss: 0.0026
grad_norm: 0.016294406726956367
learning_rate: 0.001792207792207792
epoch: 6.233766233766234


2024-09-03 01:03:38,464 - INFO - Step: 14600
loss: 0.0025
grad_norm: 0.02511603944003582
learning_rate: 0.0017893217893217895
epoch: 6.32034632034632


2024-09-03 01:06:18,272 - INFO - Step: 14800
loss: 0.0093
grad_norm: 0.02830721251666546
learning_rate: 0.0017864357864357866
epoch: 6.406926406926407


2024-09-03 01:08:57,658 - INFO - Step: 15000
loss: 0.0029
grad_norm: 0.01098011527210474
learning_rate: 0.0017835497835497836
epoch: 6.4935064935064934


2024-09-03 01:11:38,623 - INFO - Step: 15200
loss: 0.0023
grad_norm: 0.013743463903665543
learning_rate: 0.0017806637806637806
epoch: 6.58008658008658


2024-09-03 01:14:18,420 - INFO - Step: 15400
loss: 0.0024
grad_norm: 0.013854891061782837
learning_rate: 0.0017777777777777776
epoch: 6.666666666666667


2024-09-03 01:16:59,263 - INFO - Step: 15600
loss: 0.0022
grad_norm: 0.006592880003154278
learning_rate: 0.001774891774891775
epoch: 6.753246753246753


2024-09-03 01:19:38,805 - INFO - Step: 15800
loss: 0.002
grad_norm: 0.012033735401928425
learning_rate: 0.0017720057720057721
epoch: 6.83982683982684


2024-09-03 01:22:18,852 - INFO - Step: 16000
loss: 0.002
grad_norm: 0.013251465745270252
learning_rate: 0.0017691197691197692
epoch: 6.926406926406926


2024-09-03 01:27:47,994 - INFO - Step: 16170
eval_loss: 0.0018308485159650445
eval_runtime: 192.1754
eval_samples_per_second: 494.522
eval_steps_per_second: 2.576
epoch: 7.0


2024-09-03 01:28:11,728 - INFO - Step: 16200
loss: 0.0019
grad_norm: 0.008611293509602547
learning_rate: 0.0017662337662337662
epoch: 7.012987012987013


2024-09-03 01:30:51,686 - INFO - Step: 16400
loss: 0.0017
grad_norm: 0.012241031974554062
learning_rate: 0.0017633477633477634
epoch: 7.0995670995671


2024-09-03 01:33:32,786 - INFO - Step: 16600
loss: 0.0018
grad_norm: 0.009120764210820198
learning_rate: 0.0017604617604617605
epoch: 7.186147186147186


2024-09-03 01:36:12,839 - INFO - Step: 16800
loss: 0.0018
grad_norm: 0.00937526673078537
learning_rate: 0.0017575757575757577
epoch: 7.2727272727272725


2024-09-03 01:38:52,450 - INFO - Step: 17000
loss: 0.0018
grad_norm: 0.014549264684319496
learning_rate: 0.0017546897546897547
epoch: 7.359307359307359


2024-09-03 01:41:33,779 - INFO - Step: 17200
loss: 0.0018
grad_norm: 0.007106720935553312
learning_rate: 0.0017518037518037518
epoch: 7.445887445887446


2024-09-03 01:44:14,105 - INFO - Step: 17400
loss: 0.0046
grad_norm: 0.016511868685483932
learning_rate: 0.001748917748917749
epoch: 7.532467532467533


2024-09-03 01:46:55,114 - INFO - Step: 17600
loss: 0.0027
grad_norm: 0.009933596476912498
learning_rate: 0.001746031746031746
epoch: 7.619047619047619


2024-09-03 01:49:35,184 - INFO - Step: 17800
loss: 0.0024
grad_norm: 0.013865298591554165
learning_rate: 0.001743145743145743
epoch: 7.705627705627705


2024-09-03 01:52:15,353 - INFO - Step: 18000
loss: 0.0021
grad_norm: 0.01287660002708435
learning_rate: 0.0017402597402597403
epoch: 7.792207792207792


2024-09-03 01:54:56,721 - INFO - Step: 18200
loss: 0.002
grad_norm: 0.016078388318419456
learning_rate: 0.0017373737373737375
epoch: 7.878787878787879


2024-09-03 01:57:37,072 - INFO - Step: 18400
loss: 0.0019
grad_norm: 0.010167093947529793
learning_rate: 0.0017344877344877346
epoch: 7.965367965367966


2024-09-03 02:01:52,872 - INFO - Step: 18480
eval_loss: 0.0019453937420621514
eval_runtime: 191.9848
eval_samples_per_second: 495.013
eval_steps_per_second: 2.578
epoch: 8.0


2024-09-03 02:03:29,444 - INFO - Step: 18600
loss: 0.0018
grad_norm: 0.01419098675251007
learning_rate: 0.0017316017316017316
epoch: 8.051948051948052


2024-09-03 02:06:09,389 - INFO - Step: 18800
loss: 0.0017
grad_norm: 0.013775673694908619
learning_rate: 0.0017287157287157286
epoch: 8.13852813852814


2024-09-03 02:08:49,374 - INFO - Step: 19000
loss: 0.0018
grad_norm: 0.013641596771776676
learning_rate: 0.0017258297258297259
epoch: 8.225108225108226


2024-09-03 02:11:30,405 - INFO - Step: 19200
loss: 0.0017
grad_norm: 0.006551285274326801
learning_rate: 0.0017229437229437231
epoch: 8.311688311688311


2024-09-03 02:14:10,396 - INFO - Step: 19400
loss: 0.0018
grad_norm: 0.011468111537396908
learning_rate: 0.0017200577200577201
epoch: 8.398268398268398


2024-09-03 02:16:51,567 - INFO - Step: 19600
loss: 0.0018
grad_norm: 0.011401459574699402
learning_rate: 0.0017171717171717172
epoch: 8.484848484848484


2024-09-03 02:19:31,354 - INFO - Step: 19800
loss: 0.0019
grad_norm: 0.010408194735646248
learning_rate: 0.0017142857142857142
epoch: 8.571428571428571


2024-09-03 02:22:11,139 - INFO - Step: 20000
loss: 0.0019
grad_norm: 0.012699938379228115
learning_rate: 0.0017113997113997114
epoch: 8.658008658008658


2024-09-03 02:24:52,544 - INFO - Step: 20200
loss: 0.0019
grad_norm: 0.019141174852848053
learning_rate: 0.0017085137085137085
epoch: 8.744588744588745


2024-09-03 02:27:32,898 - INFO - Step: 20400
loss: 0.002
grad_norm: 0.014578751288354397
learning_rate: 0.0017056277056277057
epoch: 8.831168831168831


2024-09-03 02:30:14,091 - INFO - Step: 20600
loss: 0.002
grad_norm: 0.008031599223613739
learning_rate: 0.0017027417027417027
epoch: 8.917748917748918


2024-09-03 02:35:58,196 - INFO - Step: 20790
eval_loss: 0.0020272857509553432
eval_runtime: 192.192
eval_samples_per_second: 494.479
eval_steps_per_second: 2.576
epoch: 9.0


2024-09-03 02:36:06,128 - INFO - Step: 20800
loss: 0.002
grad_norm: 0.011094978079199791
learning_rate: 0.0016998556998557
epoch: 9.004329004329005


2024-09-03 02:38:45,663 - INFO - Step: 21000
loss: 0.0019
grad_norm: 0.014377343468368053
learning_rate: 0.001696969696969697
epoch: 9.090909090909092


2024-09-03 02:41:26,821 - INFO - Step: 21200
loss: 0.0019
grad_norm: 0.012751545757055283
learning_rate: 0.001694083694083694
epoch: 9.177489177489177


2024-09-03 02:44:06,305 - INFO - Step: 21400
loss: 0.0022
grad_norm: 0.011223064735531807
learning_rate: 0.0016911976911976913
epoch: 9.264069264069263


2024-09-03 02:46:46,912 - INFO - Step: 21600
loss: 0.002
grad_norm: 0.007026180624961853
learning_rate: 0.0016883116883116883
epoch: 9.35064935064935


2024-09-03 02:49:26,622 - INFO - Step: 21800
loss: 0.0019
grad_norm: 0.01446552388370037
learning_rate: 0.0016854256854256856
epoch: 9.437229437229437


2024-09-03 02:52:06,488 - INFO - Step: 22000
loss: 0.0019
grad_norm: 0.011017114855349064
learning_rate: 0.0016825396825396826
epoch: 9.523809523809524


2024-09-03 02:54:47,525 - INFO - Step: 22200
loss: 0.0019
grad_norm: 0.01267414353787899
learning_rate: 0.0016796536796536796
epoch: 9.61038961038961


2024-09-03 02:57:27,482 - INFO - Step: 22400
loss: 0.0019
grad_norm: 0.013120477087795734
learning_rate: 0.0016767676767676766
epoch: 9.696969696969697


2024-09-03 03:00:08,193 - INFO - Step: 22600
loss: 0.002
grad_norm: 0.007620940450578928
learning_rate: 0.001673881673881674
epoch: 9.783549783549784


2024-09-03 03:02:47,908 - INFO - Step: 22800
loss: 0.0019
grad_norm: 0.009430328384041786
learning_rate: 0.0016709956709956711
epoch: 9.87012987012987


2024-09-03 03:05:27,294 - INFO - Step: 23000
loss: 0.0019
grad_norm: 0.020826824009418488
learning_rate: 0.0016681096681096682
epoch: 9.956709956709958


2024-09-03 03:09:59,814 - INFO - Step: 23100
eval_loss: 0.002005537273362279
eval_runtime: 191.907
eval_samples_per_second: 495.214
eval_steps_per_second: 2.579
epoch: 10.0


2024-09-03 03:11:19,123 - INFO - Step: 23200
loss: 0.0018
grad_norm: 0.012186938896775246
learning_rate: 0.0016652236652236652
epoch: 10.043290043290042


2024-09-03 03:13:58,848 - INFO - Step: 23400
loss: 0.0018
grad_norm: 0.008887670934200287
learning_rate: 0.0016623376623376624
epoch: 10.12987012987013


2024-09-03 03:16:39,055 - INFO - Step: 23600
loss: 0.0018
grad_norm: 0.012135311961174011
learning_rate: 0.0016594516594516595
epoch: 10.216450216450216


2024-09-03 03:19:18,460 - INFO - Step: 23800
loss: 0.0018
grad_norm: 0.011142086237668991
learning_rate: 0.0016565656565656567
epoch: 10.303030303030303


2024-09-03 03:21:58,261 - INFO - Step: 24000
loss: 0.002
grad_norm: 0.010479352436959743
learning_rate: 0.0016536796536796537
epoch: 10.38961038961039


2024-09-03 03:24:39,004 - INFO - Step: 24200
loss: 0.0019
grad_norm: 0.006153615657240152
learning_rate: 0.0016507936507936507
epoch: 10.476190476190476


2024-09-03 03:27:18,472 - INFO - Step: 24400
loss: 0.0019
grad_norm: 0.012874636799097061
learning_rate: 0.001647907647907648
epoch: 10.562770562770563


2024-09-03 03:29:58,936 - INFO - Step: 24600
loss: 0.0019
grad_norm: 0.005367309786379337
learning_rate: 0.001645021645021645
epoch: 10.64935064935065


2024-09-03 03:32:38,053 - INFO - Step: 24800
loss: 0.0019
grad_norm: 0.008382754400372505
learning_rate: 0.001642135642135642
epoch: 10.735930735930737


2024-09-03 03:35:17,259 - INFO - Step: 25000
loss: 0.0019
grad_norm: 0.014767292886972427
learning_rate: 0.0016392496392496393
epoch: 10.822510822510823


2024-09-03 03:37:57,960 - INFO - Step: 25200
loss: 0.0018
grad_norm: 0.008209758438169956
learning_rate: 0.0016363636363636365
epoch: 10.909090909090908


2024-09-03 03:40:37,056 - INFO - Step: 25400
loss: 0.0019
grad_norm: 0.013727412559092045
learning_rate: 0.0016334776334776336
epoch: 10.995670995670995


2024-09-03 03:43:56,619 - INFO - Step: 25410
eval_loss: 0.001981615088880062
eval_runtime: 191.7244
eval_samples_per_second: 495.685
eval_steps_per_second: 2.582
epoch: 11.0


2024-09-03 03:46:28,026 - INFO - Step: 25600
loss: 0.0017
grad_norm: 0.012801325879991055
learning_rate: 0.0016305916305916306
epoch: 11.082251082251082


2024-09-03 03:49:07,236 - INFO - Step: 25800
loss: 0.0017
grad_norm: 0.0041194395162165165
learning_rate: 0.0016277056277056276
epoch: 11.168831168831169


2024-09-03 03:51:46,624 - INFO - Step: 26000
loss: 0.0017
grad_norm: 0.011391855776309967
learning_rate: 0.0016248196248196246
epoch: 11.255411255411255


2024-09-03 03:54:26,740 - INFO - Step: 26200
loss: 0.0018
grad_norm: 0.005354088731110096
learning_rate: 0.001621933621933622
epoch: 11.341991341991342


2024-09-03 03:57:06,106 - INFO - Step: 26400
loss: 0.0018
grad_norm: 0.010257511399686337
learning_rate: 0.0016190476190476191
epoch: 11.428571428571429


2024-09-03 03:59:46,572 - INFO - Step: 26600
loss: 0.0018
grad_norm: 0.009490622207522392
learning_rate: 0.0016161616161616162
epoch: 11.515151515151516


2024-09-03 04:02:26,082 - INFO - Step: 26800
loss: 0.0017
grad_norm: 0.006656943820416927
learning_rate: 0.0016132756132756132
epoch: 11.601731601731602


2024-09-03 04:05:05,544 - INFO - Step: 27000
loss: 0.0019
grad_norm: 0.010490250773727894
learning_rate: 0.0016103896103896104
epoch: 11.688311688311689


2024-09-03 04:07:45,970 - INFO - Step: 27200
loss: 0.0018
grad_norm: 0.006689255125820637
learning_rate: 0.0016075036075036077
epoch: 11.774891774891774


2024-09-03 04:10:24,633 - INFO - Step: 27400
loss: 0.0017
grad_norm: 0.014586924575269222
learning_rate: 0.0016046176046176047
epoch: 11.86147186147186


2024-09-03 04:13:04,798 - INFO - Step: 27600
loss: 0.0018
grad_norm: 0.00884226243942976
learning_rate: 0.0016017316017316017
epoch: 11.948051948051948


2024-09-03 04:17:51,452 - INFO - Step: 27720
eval_loss: 0.0019989104475826025
eval_runtime: 191.2862
eval_samples_per_second: 496.821
eval_steps_per_second: 2.588
epoch: 12.0


2024-09-03 04:18:54,247 - INFO - Step: 27800
loss: 0.0017
grad_norm: 0.004149985034018755
learning_rate: 0.0015988455988455988
epoch: 12.034632034632034


2024-09-03 04:21:32,877 - INFO - Step: 28000
loss: 0.0016
grad_norm: 0.008179965429008007
learning_rate: 0.001595959595959596
epoch: 12.121212121212121


2024-09-03 04:24:12,944 - INFO - Step: 28200
loss: 0.0017
grad_norm: 0.014387530274689198
learning_rate: 0.001593073593073593
epoch: 12.207792207792208


2024-09-03 04:26:51,526 - INFO - Step: 28400
loss: 0.0016
grad_norm: 0.013765343464910984
learning_rate: 0.0015901875901875903
epoch: 12.294372294372295


2024-09-03 04:29:31,703 - INFO - Step: 28600
loss: 0.0017
grad_norm: 0.01402051467448473
learning_rate: 0.0015873015873015873
epoch: 12.380952380952381


2024-09-03 04:32:10,494 - INFO - Step: 28800
loss: 0.0017
grad_norm: 0.016947714611887932
learning_rate: 0.0015844155844155845
epoch: 12.467532467532468


2024-09-03 04:34:49,428 - INFO - Step: 29000
loss: 0.0017
grad_norm: 0.009780874475836754
learning_rate: 0.0015815295815295816
epoch: 12.554112554112555


2024-09-03 04:37:28,754 - INFO - Step: 29200
loss: 0.0017
grad_norm: 0.006267685443162918
learning_rate: 0.0015786435786435786
epoch: 12.64069264069264


2024-09-03 04:40:07,696 - INFO - Step: 29400
loss: 0.0016
grad_norm: 0.01020876131951809
learning_rate: 0.0015757575757575756
epoch: 12.727272727272727


2024-09-03 04:42:47,507 - INFO - Step: 29600
loss: 0.0017
grad_norm: 0.0083732008934021
learning_rate: 0.001572871572871573
epoch: 12.813852813852813


2024-09-03 04:45:26,244 - INFO - Step: 29800
loss: 0.0018
grad_norm: 0.007710766512900591
learning_rate: 0.0015699855699855701
epoch: 12.9004329004329


2024-09-03 04:48:04,786 - INFO - Step: 30000
loss: 0.0018
grad_norm: 0.00916517898440361
learning_rate: 0.0015670995670995671
epoch: 12.987012987012987


2024-09-03 04:51:40,436 - INFO - Step: 30030
eval_loss: 0.0019240990513935685
eval_runtime: 190.9915
eval_samples_per_second: 497.588
eval_steps_per_second: 2.592
epoch: 13.0


2024-09-03 04:53:55,231 - INFO - Step: 30200
loss: 0.0015
grad_norm: 0.007637326605618
learning_rate: 0.0015642135642135642
epoch: 13.073593073593074


2024-09-03 04:56:34,056 - INFO - Step: 30400
loss: 0.0015
grad_norm: 0.018825272098183632
learning_rate: 0.0015613275613275612
epoch: 13.16017316017316


2024-09-03 04:59:13,697 - INFO - Step: 30600
loss: 0.0015
grad_norm: 0.0062187728472054005
learning_rate: 0.0015584415584415587
epoch: 13.246753246753247


2024-09-03 05:01:52,324 - INFO - Step: 30800
loss: 0.0016
grad_norm: 0.00538305938243866
learning_rate: 0.0015555555555555557
epoch: 13.333333333333334


2024-09-03 05:04:30,774 - INFO - Step: 31000
loss: 0.0016
grad_norm: 0.010058391839265823
learning_rate: 0.0015526695526695527
epoch: 13.41991341991342


2024-09-03 05:07:10,325 - INFO - Step: 31200
loss: 0.0016
grad_norm: 0.006436267867684364
learning_rate: 0.0015497835497835497
epoch: 13.506493506493506


2024-09-03 05:09:48,891 - INFO - Step: 31400
loss: 0.0016
grad_norm: 0.005856317467987537
learning_rate: 0.001546897546897547
epoch: 13.593073593073592


2024-09-03 05:12:28,461 - INFO - Step: 31600
loss: 0.0015
grad_norm: 0.007258167490363121
learning_rate: 0.001544011544011544
epoch: 13.67965367965368


2024-09-03 05:15:06,970 - INFO - Step: 31800
loss: 0.0016
grad_norm: 0.007386224344372749
learning_rate: 0.0015411255411255413
epoch: 13.766233766233766


2024-09-03 05:17:45,312 - INFO - Step: 32000
loss: 0.0016
grad_norm: 0.011980871669948101
learning_rate: 0.0015382395382395383
epoch: 13.852813852813853


2024-09-03 05:20:24,690 - INFO - Step: 32200
loss: 0.0016
grad_norm: 0.007597645279020071
learning_rate: 0.0015353535353535353
epoch: 13.93939393939394


2024-09-03 05:25:26,725 - INFO - Step: 32340
eval_loss: 0.001948151970282197
eval_runtime: 191.2022
eval_samples_per_second: 497.039
eval_steps_per_second: 2.589
epoch: 14.0


2024-09-03 05:26:13,692 - INFO - Step: 32400
loss: 0.0015
grad_norm: 0.00933520495891571
learning_rate: 0.0015324675324675326
epoch: 14.025974025974026


2024-09-03 05:28:52,707 - INFO - Step: 32600
loss: 0.0014
grad_norm: 0.006358820479363203
learning_rate: 0.0015295815295815296
epoch: 14.112554112554113


2024-09-03 05:31:30,132 - INFO - Step: 32800
loss: 0.0014
grad_norm: 0.0060053858906030655
learning_rate: 0.0015266955266955266
epoch: 14.1991341991342


2024-09-03 05:34:08,155 - INFO - Step: 33000
loss: 0.0015
grad_norm: 0.0057709733955562115
learning_rate: 0.0015238095238095239
epoch: 14.285714285714286


2024-09-03 05:36:47,544 - INFO - Step: 33200
loss: 0.0015
grad_norm: 0.005310382694005966
learning_rate: 0.001520923520923521
epoch: 14.372294372294371


2024-09-03 05:39:25,440 - INFO - Step: 33400
loss: 0.0015
grad_norm: 0.0096222423017025
learning_rate: 0.0015180375180375181
epoch: 14.458874458874458


2024-09-03 05:42:04,095 - INFO - Step: 33600
loss: 0.0015
grad_norm: 0.00921886507421732
learning_rate: 0.0015151515151515152
epoch: 14.545454545454545


2024-09-03 05:44:42,311 - INFO - Step: 33800
loss: 0.0015
grad_norm: 0.022553440183401108
learning_rate: 0.0015122655122655122
epoch: 14.632034632034632


2024-09-03 05:47:20,643 - INFO - Step: 34000
loss: 0.0015
grad_norm: 0.005056699737906456
learning_rate: 0.0015093795093795094
epoch: 14.718614718614718


2024-09-03 05:50:00,158 - INFO - Step: 34200
loss: 0.0015
grad_norm: 0.010686712339520454
learning_rate: 0.0015064935064935067
epoch: 14.805194805194805


2024-09-03 05:52:38,434 - INFO - Step: 34400
loss: 0.0016
grad_norm: 0.010862767696380615
learning_rate: 0.0015036075036075037
epoch: 14.891774891774892


2024-09-03 05:55:16,692 - INFO - Step: 34600
loss: 0.0016
grad_norm: 0.009425131604075432
learning_rate: 0.0015007215007215007
epoch: 14.978354978354979


2024-09-03 05:59:06,686 - INFO - Step: 34650
eval_loss: 0.0019768320489674807
eval_runtime: 190.7098
eval_samples_per_second: 498.323
eval_steps_per_second: 2.596
epoch: 15.0


2024-09-03 06:01:04,491 - INFO - Step: 34800
loss: 0.0015
grad_norm: 0.004650297109037638
learning_rate: 0.0014978354978354977
epoch: 15.064935064935066


2024-09-03 06:03:41,997 - INFO - Step: 35000
loss: 0.0014
grad_norm: 0.0060159554705023766
learning_rate: 0.001494949494949495
epoch: 15.151515151515152


2024-09-03 06:06:20,663 - INFO - Step: 35200
loss: 0.0014
grad_norm: 0.008641461841762066
learning_rate: 0.001492063492063492
epoch: 15.238095238095237


2024-09-03 06:08:58,395 - INFO - Step: 35400
loss: 0.0014
grad_norm: 0.007835905067622662
learning_rate: 0.0014891774891774893
epoch: 15.324675324675324


2024-09-03 06:11:37,053 - INFO - Step: 35600
loss: 0.0014
grad_norm: 0.00619752099737525
learning_rate: 0.0014862914862914863
epoch: 15.41125541125541


2024-09-03 06:14:15,097 - INFO - Step: 35800
loss: 0.0016
grad_norm: 0.018233440816402435
learning_rate: 0.0014834054834054835
epoch: 15.497835497835498


2024-09-03 06:16:52,937 - INFO - Step: 36000
loss: 0.0017
grad_norm: 0.015481598675251007
learning_rate: 0.0014805194805194806
epoch: 15.584415584415584


2024-09-03 06:19:32,681 - INFO - Step: 36200
loss: 0.0014
grad_norm: 0.008267289958894253
learning_rate: 0.0014776334776334776
epoch: 15.670995670995671


2024-09-03 06:22:11,523 - INFO - Step: 36400
loss: 0.0015
grad_norm: 0.007871710695326328
learning_rate: 0.0014747474747474748
epoch: 15.757575757575758


2024-09-03 06:24:50,362 - INFO - Step: 36600
loss: 0.0014
grad_norm: 0.005373268388211727
learning_rate: 0.0014718614718614719
epoch: 15.844155844155845


2024-09-03 06:27:28,349 - INFO - Step: 36800
loss: 0.0015
grad_norm: 0.006282958667725325
learning_rate: 0.001468975468975469
epoch: 15.930735930735931


2024-09-03 06:32:45,865 - INFO - Step: 36960
eval_loss: 0.00196106918156147
eval_runtime: 190.5975
eval_samples_per_second: 498.616
eval_steps_per_second: 2.597
epoch: 16.0


2024-09-03 06:33:17,297 - INFO - Step: 37000
loss: 0.0015
grad_norm: 0.009554270654916763
learning_rate: 0.0014660894660894661
epoch: 16.017316017316016


2024-09-03 06:35:56,840 - INFO - Step: 37200
loss: 0.0012
grad_norm: 0.006579694803804159
learning_rate: 0.0014632034632034632
epoch: 16.103896103896105


2024-09-03 06:38:35,360 - INFO - Step: 37400
loss: 0.0013
grad_norm: 0.008992291055619717
learning_rate: 0.0014603174603174602
epoch: 16.19047619047619


2024-09-03 06:41:14,766 - INFO - Step: 37600
loss: 0.0013
grad_norm: 0.012256021611392498
learning_rate: 0.0014574314574314576
epoch: 16.27705627705628


2024-09-03 06:43:53,377 - INFO - Step: 37800
loss: 0.0013
grad_norm: 0.009232922457158566
learning_rate: 0.0014545454545454547
epoch: 16.363636363636363


2024-09-03 06:46:31,946 - INFO - Step: 38000
loss: 0.0014
grad_norm: 0.005819201003760099
learning_rate: 0.0014516594516594517
epoch: 16.450216450216452


2024-09-03 06:49:11,557 - INFO - Step: 38200
loss: 0.0014
grad_norm: 0.005372297018766403
learning_rate: 0.0014487734487734487
epoch: 16.536796536796537


2024-09-03 06:51:50,046 - INFO - Step: 38400
loss: 0.0014
grad_norm: 0.00943985115736723
learning_rate: 0.0014458874458874458
epoch: 16.623376623376622


2024-09-03 06:54:29,340 - INFO - Step: 38600
loss: 0.0014
grad_norm: 0.0064231352880597115
learning_rate: 0.001443001443001443
epoch: 16.70995670995671


2024-09-03 06:57:07,491 - INFO - Step: 38800
loss: 0.0014
grad_norm: 0.004948500543832779
learning_rate: 0.0014401154401154402
epoch: 16.796536796536795


2024-09-03 06:59:45,568 - INFO - Step: 39000
loss: 0.0014
grad_norm: 0.010160716250538826
learning_rate: 0.0014372294372294373
epoch: 16.883116883116884


2024-09-03 07:02:24,485 - INFO - Step: 39200
loss: 0.0014
grad_norm: 0.009010488167405128
learning_rate: 0.0014343434343434343
epoch: 16.96969696969697


2024-09-03 07:06:30,122 - INFO - Step: 39270
eval_loss: 0.001986767165362835
eval_runtime: 190.3941
eval_samples_per_second: 499.149
eval_steps_per_second: 2.6
epoch: 17.0


2024-09-03 07:08:12,685 - INFO - Step: 39400
loss: 0.0013
grad_norm: 0.006991517264395952
learning_rate: 0.0014314574314574315
epoch: 17.056277056277057


2024-09-03 07:10:51,260 - INFO - Step: 39600
loss: 0.0013
grad_norm: 0.010740956291556358
learning_rate: 0.0014285714285714286
epoch: 17.142857142857142


2024-09-03 07:13:28,726 - INFO - Step: 39800
loss: 0.0013
grad_norm: 0.005899952724575996
learning_rate: 0.0014256854256854256
epoch: 17.22943722943723


2024-09-03 07:16:06,797 - INFO - Step: 40000
loss: 0.0013
grad_norm: 0.004286185838282108
learning_rate: 0.0014227994227994228
epoch: 17.316017316017316


2024-09-03 07:18:45,067 - INFO - Step: 40200
loss: 0.0013
grad_norm: 0.006387597881257534
learning_rate: 0.00141991341991342
epoch: 17.4025974025974


2024-09-03 07:21:22,659 - INFO - Step: 40400
loss: 0.0013
grad_norm: 0.007442019879817963
learning_rate: 0.0014170274170274171
epoch: 17.48917748917749


2024-09-03 07:24:01,151 - INFO - Step: 40600
loss: 0.0013
grad_norm: 0.006327924784272909
learning_rate: 0.0014141414141414141
epoch: 17.575757575757574


2024-09-03 07:26:38,737 - INFO - Step: 40800
loss: 0.0014
grad_norm: 0.0068632690235972404
learning_rate: 0.0014112554112554112
epoch: 17.662337662337663


2024-09-03 07:29:16,007 - INFO - Step: 41000
loss: 0.0014
grad_norm: 0.004115037154406309
learning_rate: 0.0014083694083694082
epoch: 17.748917748917748


2024-09-03 07:31:54,608 - INFO - Step: 41200
loss: 0.0014
grad_norm: 0.009591699577867985
learning_rate: 0.0014054834054834057
epoch: 17.835497835497836


2024-09-03 07:34:32,017 - INFO - Step: 41400
loss: 0.0014
grad_norm: 0.005738328211009502
learning_rate: 0.0014025974025974027
epoch: 17.92207792207792


2024-09-03 07:40:05,578 - INFO - Step: 41580
eval_loss: 0.002051650546491146
eval_runtime: 190.6935
eval_samples_per_second: 498.365
eval_steps_per_second: 2.596
epoch: 18.0


2024-09-03 07:40:21,353 - INFO - Step: 41600
loss: 0.0013
grad_norm: 0.00643604900687933
learning_rate: 0.0013997113997113997
epoch: 18.00865800865801


2024-09-03 07:42:59,450 - INFO - Step: 41800
loss: 0.0012
grad_norm: 0.012306303717195988
learning_rate: 0.0013968253968253967
epoch: 18.095238095238095


2024-09-03 07:45:37,877 - INFO - Step: 42000
loss: 0.0013
grad_norm: 0.008666763082146645
learning_rate: 0.001393939393939394
epoch: 18.181818181818183


2024-09-03 07:48:17,227 - INFO - Step: 42200
loss: 0.0012
grad_norm: 0.008130551315844059
learning_rate: 0.0013910533910533912
epoch: 18.26839826839827


2024-09-03 07:50:55,645 - INFO - Step: 42400
loss: 0.0012
grad_norm: 0.0055084191262722015
learning_rate: 0.0013881673881673883
epoch: 18.354978354978353


2024-09-03 07:53:34,840 - INFO - Step: 42600
loss: 0.0013
grad_norm: 0.006948789115995169
learning_rate: 0.0013852813852813853
epoch: 18.441558441558442


2024-09-03 07:56:13,027 - INFO - Step: 42800
loss: 0.0013
grad_norm: 0.005131819285452366
learning_rate: 0.0013823953823953823
epoch: 18.528138528138527


2024-09-03 07:58:51,313 - INFO - Step: 43000
loss: 0.0013
grad_norm: 0.006879775319248438
learning_rate: 0.0013795093795093796
epoch: 18.614718614718615


2024-09-03 08:01:30,659 - INFO - Step: 43200
loss: 0.0013
grad_norm: 0.009008001536130905
learning_rate: 0.0013766233766233766
epoch: 18.7012987012987


2024-09-03 08:04:08,964 - INFO - Step: 43400
loss: 0.0013
grad_norm: 0.00450183916836977
learning_rate: 0.0013737373737373738
epoch: 18.78787878787879


2024-09-03 08:06:48,470 - INFO - Step: 43600
loss: 0.0014
grad_norm: 0.00455572921782732
learning_rate: 0.0013708513708513709
epoch: 18.874458874458874


2024-09-03 08:09:26,666 - INFO - Step: 43800
loss: 0.0014
grad_norm: 0.00605141231790185
learning_rate: 0.001367965367965368
epoch: 18.961038961038962


2024-09-03 08:13:48,607 - INFO - Step: 43890
eval_loss: 0.002078372286632657
eval_runtime: 190.7582
eval_samples_per_second: 498.196
eval_steps_per_second: 2.595
epoch: 19.0


2024-09-03 08:15:14,937 - INFO - Step: 44000
loss: 0.0013
grad_norm: 0.008709774352610111
learning_rate: 0.0013650793650793651
epoch: 19.047619047619047


2024-09-03 08:17:53,573 - INFO - Step: 44200
loss: 0.0012
grad_norm: 0.0073007624596357346
learning_rate: 0.0013621933621933621
epoch: 19.134199134199136


2024-09-03 08:20:31,594 - INFO - Step: 44400
loss: 0.0012
grad_norm: 0.008069182746112347
learning_rate: 0.0013593073593073592
epoch: 19.22077922077922


2024-09-03 08:23:10,878 - INFO - Step: 44600
loss: 0.0011
grad_norm: 0.0074763610027730465
learning_rate: 0.0013564213564213566
epoch: 19.307359307359306


2024-09-03 08:25:48,639 - INFO - Step: 44800
loss: 0.0012
grad_norm: 0.006379237398505211
learning_rate: 0.0013535353535353537
epoch: 19.393939393939394


2024-09-03 08:28:26,123 - INFO - Step: 45000
loss: 0.0012
grad_norm: 0.007463953457772732
learning_rate: 0.0013506493506493507
epoch: 19.48051948051948


2024-09-03 08:31:05,677 - INFO - Step: 45200
loss: 0.0012
grad_norm: 0.00790778174996376
learning_rate: 0.0013477633477633477
epoch: 19.567099567099568


2024-09-03 08:33:43,571 - INFO - Step: 45400
loss: 0.0012
grad_norm: 0.006628876551985741
learning_rate: 0.0013448773448773447
epoch: 19.653679653679653


2024-09-03 08:36:22,159 - INFO - Step: 45600
loss: 0.0013
grad_norm: 0.006014412734657526
learning_rate: 0.001341991341991342
epoch: 19.74025974025974


2024-09-03 08:38:59,845 - INFO - Step: 45800
loss: 0.0014
grad_norm: 0.006361900828778744
learning_rate: 0.0013391053391053392
epoch: 19.826839826839826


2024-09-03 08:41:37,060 - INFO - Step: 46000
loss: 0.0013
grad_norm: 0.008459757082164288
learning_rate: 0.0013362193362193363
epoch: 19.913419913419915


2024-09-03 08:44:15,449 - INFO - Step: 46200
loss: 0.0013
grad_norm: 0.007371259853243828
learning_rate: 0.0013333333333333333
epoch: 20.0


2024-09-03 08:47:25,946 - INFO - Step: 46200
eval_loss: 0.002006880007684231
eval_runtime: 190.4956
eval_samples_per_second: 498.883
eval_steps_per_second: 2.598
epoch: 20.0


2024-09-03 08:50:03,459 - INFO - Step: 46400
loss: 0.0011
grad_norm: 0.005380354356020689
learning_rate: 0.0013304473304473305
epoch: 20.086580086580085


2024-09-03 08:52:42,596 - INFO - Step: 46600
loss: 0.0011
grad_norm: 0.004770553205162287
learning_rate: 0.0013275613275613276
epoch: 20.173160173160174


2024-09-03 08:55:19,520 - INFO - Step: 46800
loss: 0.0011
grad_norm: 0.006060207728296518
learning_rate: 0.0013246753246753248
epoch: 20.25974025974026


2024-09-03 08:57:57,292 - INFO - Step: 47000
loss: 0.0012
grad_norm: 0.0034496698062866926
learning_rate: 0.0013217893217893218
epoch: 20.346320346320347


2024-09-03 09:00:35,957 - INFO - Step: 47200
loss: 0.0012
grad_norm: 0.027267485857009888
learning_rate: 0.0013189033189033189
epoch: 20.432900432900432


2024-09-03 09:03:13,801 - INFO - Step: 47400
loss: 0.0012
grad_norm: 0.0044079795479774475
learning_rate: 0.001316017316017316
epoch: 20.51948051948052


2024-09-03 09:05:52,198 - INFO - Step: 47600
loss: 0.0012
grad_norm: 0.010142641142010689
learning_rate: 0.0013131313131313131
epoch: 20.606060606060606


2024-09-03 09:08:29,396 - INFO - Step: 47800
loss: 0.0012
grad_norm: 0.005792264826595783
learning_rate: 0.0013102453102453102
epoch: 20.692640692640694


2024-09-03 09:11:07,489 - INFO - Step: 48000
loss: 0.0031
grad_norm: 0.016114065423607826
learning_rate: 0.0013073593073593074
epoch: 20.77922077922078


2024-09-03 09:13:47,435 - INFO - Step: 48200
loss: 0.0015
grad_norm: 0.009099376387894154
learning_rate: 0.0013044733044733046
epoch: 20.865800865800864


2024-09-03 09:16:26,722 - INFO - Step: 48400
loss: 0.0013
grad_norm: 0.010533339343965054
learning_rate: 0.0013015873015873017
epoch: 20.952380952380953


2024-09-03 09:21:05,605 - INFO - Step: 48510
eval_loss: 0.0019151850137859583
eval_runtime: 190.476
eval_samples_per_second: 498.934
eval_steps_per_second: 2.599
epoch: 21.0


2024-09-03 09:22:16,752 - INFO - Step: 48600
loss: 0.0011
grad_norm: 0.004939584527164698
learning_rate: 0.0012987012987012987
epoch: 21.038961038961038


2024-09-03 09:24:55,402 - INFO - Step: 48800
loss: 0.001
grad_norm: 0.005409374833106995
learning_rate: 0.0012958152958152957
epoch: 21.125541125541126


2024-09-03 09:27:34,352 - INFO - Step: 49000
loss: 0.001
grad_norm: 0.003992947284132242
learning_rate: 0.001292929292929293
epoch: 21.21212121212121


2024-09-03 09:30:14,160 - INFO - Step: 49200
loss: 0.001
grad_norm: 0.005676492117345333
learning_rate: 0.0012900432900432902
epoch: 21.2987012987013


2024-09-03 09:32:53,062 - INFO - Step: 49400
loss: 0.001
grad_norm: 0.004402598831802607
learning_rate: 0.0012871572871572872
epoch: 21.385281385281385


2024-09-03 09:35:32,822 - INFO - Step: 49600
loss: 0.0011
grad_norm: 0.007607860025018454
learning_rate: 0.0012842712842712843
epoch: 21.471861471861473


2024-09-03 09:38:11,902 - INFO - Step: 49800
loss: 0.001
grad_norm: 0.003178991377353668
learning_rate: 0.0012813852813852813
epoch: 21.558441558441558


2024-09-03 09:40:50,972 - INFO - Step: 50000
loss: 0.001
grad_norm: 0.0047193728387355804
learning_rate: 0.0012784992784992785
epoch: 21.645021645021647


2024-09-03 09:43:30,958 - INFO - Step: 50200
loss: 0.0011
grad_norm: 0.00906881969422102
learning_rate: 0.0012756132756132756
epoch: 21.73160173160173


2024-09-03 09:46:09,934 - INFO - Step: 50400
loss: 0.0011
grad_norm: 0.005031665787100792
learning_rate: 0.0012727272727272728
epoch: 21.818181818181817


2024-09-03 09:48:49,835 - INFO - Step: 50600
loss: 0.0011
grad_norm: 0.007110747043043375
learning_rate: 0.0012698412698412698
epoch: 21.904761904761905


2024-09-03 09:51:28,643 - INFO - Step: 50800
loss: 0.0012
grad_norm: 0.0077064563520252705
learning_rate: 0.001266955266955267
epoch: 21.99134199134199


2024-09-03 09:54:55,198 - INFO - Step: 50820
eval_loss: 0.002043279819190502
eval_runtime: 190.8546
eval_samples_per_second: 497.945
eval_steps_per_second: 2.594
epoch: 22.0


2024-09-03 09:57:17,934 - INFO - Step: 51000
loss: 0.001
grad_norm: 0.0071871536783874035
learning_rate: 0.0012640692640692641
epoch: 22.07792207792208


2024-09-03 09:59:57,473 - INFO - Step: 51200
loss: 0.001
grad_norm: 0.011793354526162148
learning_rate: 0.0012611832611832611
epoch: 22.164502164502164


2024-09-03 10:02:35,639 - INFO - Step: 51400
loss: 0.001
grad_norm: 0.0069552999921143055
learning_rate: 0.0012582972582972582
epoch: 22.251082251082252


2024-09-03 10:05:15,034 - INFO - Step: 51600
loss: 0.0011
grad_norm: 0.005111298989504576
learning_rate: 0.0012554112554112554
epoch: 22.337662337662337


2024-09-03 10:07:53,740 - INFO - Step: 51800
loss: 0.001
grad_norm: 0.0076493374072015285
learning_rate: 0.0012525252525252527
epoch: 22.424242424242426


2024-09-03 10:10:32,326 - INFO - Step: 52000
loss: 0.0011
grad_norm: 0.006794067565351725
learning_rate: 0.0012496392496392497
epoch: 22.51082251082251


2024-09-03 10:13:12,089 - INFO - Step: 52200
loss: 0.0011
grad_norm: 0.008383559994399548
learning_rate: 0.0012467532467532467
epoch: 22.5974025974026


2024-09-03 10:15:50,870 - INFO - Step: 52400
loss: 0.0011
grad_norm: 0.0059656440280377865
learning_rate: 0.0012438672438672437
epoch: 22.683982683982684


2024-09-03 10:18:30,327 - INFO - Step: 52600
loss: 0.0011
grad_norm: 0.009447110816836357
learning_rate: 0.0012409812409812412
epoch: 22.77056277056277


2024-09-03 10:21:08,408 - INFO - Step: 52800
loss: 0.0011
grad_norm: 0.011083358898758888
learning_rate: 0.0012380952380952382
epoch: 22.857142857142858


2024-09-03 10:23:46,958 - INFO - Step: 53000
loss: 0.0011
grad_norm: 0.012086445465683937
learning_rate: 0.0012352092352092353
epoch: 22.943722943722943


2024-09-03 10:28:41,833 - INFO - Step: 53130
eval_loss: 0.001945387339219451
eval_runtime: 190.744
eval_samples_per_second: 498.233
eval_steps_per_second: 2.595
epoch: 23.0


2024-09-03 10:29:37,127 - INFO - Step: 53200
loss: 0.0011
grad_norm: 0.006032741628587246
learning_rate: 0.0012323232323232323
epoch: 23.03030303030303


2024-09-03 10:32:15,767 - INFO - Step: 53400
loss: 0.0009
grad_norm: 0.00725226104259491
learning_rate: 0.0012294372294372293
epoch: 23.116883116883116


2024-09-03 10:34:54,984 - INFO - Step: 53600
loss: 0.001
grad_norm: 0.010771665722131729
learning_rate: 0.0012265512265512266
epoch: 23.203463203463205


2024-09-03 10:37:33,941 - INFO - Step: 53800
loss: 0.0011
grad_norm: 0.006238293368369341
learning_rate: 0.0012236652236652238
epoch: 23.29004329004329


2024-09-03 10:40:12,488 - INFO - Step: 54000
loss: 0.0011
grad_norm: 0.0052866083569824696
learning_rate: 0.0012207792207792208
epoch: 23.376623376623378


2024-09-03 10:42:51,751 - INFO - Step: 54200
loss: 0.0011
grad_norm: 0.004686638712882996
learning_rate: 0.0012178932178932178
epoch: 23.463203463203463


2024-09-03 10:45:30,113 - INFO - Step: 54400
loss: 0.0011
grad_norm: 0.008386305533349514
learning_rate: 0.001215007215007215
epoch: 23.549783549783548


2024-09-03 10:48:08,849 - INFO - Step: 54600
loss: 0.0011
grad_norm: 0.009295766241848469
learning_rate: 0.0012121212121212121
epoch: 23.636363636363637


2024-09-03 10:50:46,956 - INFO - Step: 54800
loss: 0.0011
grad_norm: 0.009340029209852219
learning_rate: 0.0012092352092352091
epoch: 23.72294372294372


2024-09-03 10:53:25,602 - INFO - Step: 55000
loss: 0.0011
grad_norm: 0.004881694912910461
learning_rate: 0.0012063492063492064
epoch: 23.80952380952381


2024-09-03 10:56:05,660 - INFO - Step: 55200
loss: 0.0011
grad_norm: 0.002578609623014927
learning_rate: 0.0012034632034632036
epoch: 23.896103896103895


2024-09-03 10:58:44,229 - INFO - Step: 55400
loss: 0.0011
grad_norm: 0.007312650326639414
learning_rate: 0.0012005772005772007
epoch: 23.982683982683984


2024-09-03 11:02:26,741 - INFO - Step: 55440
eval_loss: 0.0019707847386598587
eval_runtime: 190.8496
eval_samples_per_second: 497.958
eval_steps_per_second: 2.594
epoch: 24.0


2024-09-03 11:04:34,295 - INFO - Step: 55600
loss: 0.0009
grad_norm: 0.0050310418009757996
learning_rate: 0.0011976911976911977
epoch: 24.06926406926407


2024-09-03 11:07:12,742 - INFO - Step: 55800
loss: 0.0009
grad_norm: 0.015071838162839413
learning_rate: 0.0011948051948051947
epoch: 24.155844155844157


2024-09-03 11:09:51,219 - INFO - Step: 56000
loss: 0.001
grad_norm: 0.004368920810520649
learning_rate: 0.0011919191919191917
epoch: 24.242424242424242


2024-09-03 11:12:30,330 - INFO - Step: 56200
loss: 0.001
grad_norm: 0.0036470829509198666
learning_rate: 0.0011890331890331892
epoch: 24.32900432900433


2024-09-03 11:15:08,771 - INFO - Step: 56400
loss: 0.001
grad_norm: 0.004753411281853914
learning_rate: 0.0011861471861471862
epoch: 24.415584415584416


2024-09-03 11:17:47,840 - INFO - Step: 56600
loss: 0.001
grad_norm: 0.005812554620206356
learning_rate: 0.0011832611832611833
epoch: 24.5021645021645


2024-09-03 11:20:25,733 - INFO - Step: 56800
loss: 0.001
grad_norm: 0.0064734043553471565
learning_rate: 0.0011803751803751803
epoch: 24.58874458874459


2024-09-03 11:23:04,070 - INFO - Step: 57000
loss: 0.001
grad_norm: 0.0033961592707782984
learning_rate: 0.0011774891774891775
epoch: 24.675324675324674


2024-09-03 11:25:43,849 - INFO - Step: 57200
loss: 0.001
grad_norm: 0.006136673502624035
learning_rate: 0.0011746031746031748
epoch: 24.761904761904763


2024-09-03 11:28:22,426 - INFO - Step: 57400
loss: 0.0011
grad_norm: 0.008197887800633907
learning_rate: 0.0011717171717171718
epoch: 24.848484848484848


2024-09-03 11:31:01,907 - INFO - Step: 57600
loss: 0.0011
grad_norm: 0.007420931477099657
learning_rate: 0.0011688311688311688
epoch: 24.935064935064936


2024-09-03 11:36:10,949 - INFO - Step: 57750
eval_loss: 0.002022914122790098
eval_runtime: 190.5354
eval_samples_per_second: 498.779
eval_steps_per_second: 2.598
epoch: 25.0


2024-09-03 11:36:50,178 - INFO - Step: 57800
loss: 0.001
grad_norm: 0.004414769820868969
learning_rate: 0.0011659451659451659
epoch: 25.02164502164502


2024-09-03 11:39:28,631 - INFO - Step: 58000
loss: 0.0009
grad_norm: 0.0024018757976591587
learning_rate: 0.001163059163059163
epoch: 25.10822510822511


2024-09-03 11:42:08,318 - INFO - Step: 58200
loss: 0.0009
grad_norm: 0.006690666079521179
learning_rate: 0.0011601731601731601
epoch: 25.194805194805195


2024-09-03 11:44:46,593 - INFO - Step: 58400
loss: 0.0009
grad_norm: 0.0038438187912106514
learning_rate: 0.0011572871572871574
epoch: 25.28138528138528


2024-09-03 11:47:25,772 - INFO - Step: 58600
loss: 0.001
grad_norm: 0.0033771705348044634
learning_rate: 0.0011544011544011544
epoch: 25.36796536796537


2024-09-03 11:50:03,749 - INFO - Step: 58800
loss: 0.001
grad_norm: 0.004902527667582035
learning_rate: 0.0011515151515151516
epoch: 25.454545454545453


2024-09-03 11:52:41,376 - INFO - Step: 59000
loss: 0.001
grad_norm: 0.003594609908759594
learning_rate: 0.0011486291486291487
epoch: 25.541125541125542


2024-09-03 11:55:20,207 - INFO - Step: 59200
loss: 0.001
grad_norm: 0.007873534224927425
learning_rate: 0.0011457431457431457
epoch: 25.627705627705627


2024-09-03 11:57:58,851 - INFO - Step: 59400
loss: 0.001
grad_norm: 0.009302817285060883
learning_rate: 0.0011428571428571427
epoch: 25.714285714285715


2024-09-03 12:00:38,427 - INFO - Step: 59600
loss: 0.001
grad_norm: 0.004869142547249794
learning_rate: 0.0011399711399711402
epoch: 25.8008658008658


2024-09-03 12:03:16,932 - INFO - Step: 59800
loss: 0.0009
grad_norm: 0.008357163518667221
learning_rate: 0.0011370851370851372
epoch: 25.88744588744589


2024-09-03 12:05:55,349 - INFO - Step: 60000
loss: 0.001
grad_norm: 0.005949291400611401
learning_rate: 0.0011341991341991342
epoch: 25.974025974025974


2024-09-03 12:09:54,368 - INFO - Step: 60060
eval_loss: 0.0020359966438263655
eval_runtime: 190.5509
eval_samples_per_second: 498.738
eval_steps_per_second: 2.598
epoch: 26.0


2024-09-03 12:11:44,830 - INFO - Step: 60200
loss: 0.0009
grad_norm: 0.00417000288143754
learning_rate: 0.0011313131313131313
epoch: 26.060606060606062


2024-09-03 12:14:23,473 - INFO - Step: 60400
loss: 0.0008
grad_norm: 0.00461428239941597
learning_rate: 0.0011284271284271283
epoch: 26.147186147186147


2024-09-03 12:17:02,914 - INFO - Step: 60600
loss: 0.0009
grad_norm: 0.00605417788028717
learning_rate: 0.0011255411255411255
epoch: 26.233766233766232


2024-09-03 12:19:41,471 - INFO - Step: 60800
loss: 0.0009
grad_norm: 0.0038013870362192392
learning_rate: 0.0011226551226551228
epoch: 26.32034632034632


2024-09-03 12:22:20,242 - INFO - Step: 61000
loss: 0.0009
grad_norm: 0.007342201191931963
learning_rate: 0.0011197691197691198
epoch: 26.406926406926406


2024-09-03 12:24:59,842 - INFO - Step: 61200
loss: 0.0009
grad_norm: 0.004510005470365286
learning_rate: 0.0011168831168831168
epoch: 26.493506493506494


2024-09-03 12:27:38,366 - INFO - Step: 61400
loss: 0.001
grad_norm: 0.0026259098667651415
learning_rate: 0.001113997113997114
epoch: 26.58008658008658


2024-09-03 12:30:18,080 - INFO - Step: 61600
loss: 0.001
grad_norm: 0.0038022773806005716
learning_rate: 0.0011111111111111111
epoch: 26.666666666666668


2024-09-03 12:32:56,829 - INFO - Step: 61800
loss: 0.0009
grad_norm: 0.00601310795173049
learning_rate: 0.0011082251082251084
epoch: 26.753246753246753


2024-09-03 12:35:35,799 - INFO - Step: 62000
loss: 0.0009
grad_norm: 0.005393995437771082
learning_rate: 0.0011053391053391054
epoch: 26.83982683982684


2024-09-03 12:38:15,330 - INFO - Step: 62200
loss: 0.001
grad_norm: 0.004371393471956253
learning_rate: 0.0011024531024531024
epoch: 26.926406926406926


2024-09-03 12:43:40,169 - INFO - Step: 62370
eval_loss: 0.002098213182762265
eval_runtime: 190.4377
eval_samples_per_second: 499.034
eval_steps_per_second: 2.599
epoch: 27.0


2024-09-03 12:44:03,805 - INFO - Step: 62400
loss: 0.001
grad_norm: 0.006738004274666309
learning_rate: 0.0010995670995670997
epoch: 27.01298701298701


2024-09-03 12:46:43,411 - INFO - Step: 62600
loss: 0.0008
grad_norm: 0.0030059837736189365
learning_rate: 0.0010966810966810967
epoch: 27.0995670995671


2024-09-03 12:49:22,023 - INFO - Step: 62800
loss: 0.0008
grad_norm: 0.008978746831417084
learning_rate: 0.0010937950937950937
epoch: 27.186147186147185


2024-09-03 12:52:00,765 - INFO - Step: 63000
loss: 0.0009
grad_norm: 0.005676706787198782
learning_rate: 0.001090909090909091
epoch: 27.272727272727273


2024-09-03 12:54:40,287 - INFO - Step: 63200
loss: 0.0009
grad_norm: 0.003291340311989188
learning_rate: 0.0010880230880230882
epoch: 27.35930735930736


2024-09-03 12:57:19,008 - INFO - Step: 63400
loss: 0.0008
grad_norm: 0.00355867319740355
learning_rate: 0.0010851370851370852
epoch: 27.445887445887447


2024-09-03 12:59:58,350 - INFO - Step: 63600
loss: 0.0009
grad_norm: 0.0038965034764260054
learning_rate: 0.0010822510822510823
epoch: 27.532467532467532


2024-09-03 13:02:36,941 - INFO - Step: 63800
loss: 0.0009
grad_norm: 0.006309302989393473
learning_rate: 0.0010793650793650793
epoch: 27.61904761904762


2024-09-03 13:05:15,315 - INFO - Step: 64000
loss: 0.0009
grad_norm: 0.00404607318341732
learning_rate: 0.0010764790764790763
epoch: 27.705627705627705


2024-09-03 13:07:54,784 - INFO - Step: 64200
loss: 0.0009
grad_norm: 0.005231757648289204
learning_rate: 0.0010735930735930738
epoch: 27.792207792207794


2024-09-03 13:10:33,661 - INFO - Step: 64400
loss: 0.0009
grad_norm: 0.0031616906635463238
learning_rate: 0.0010707070707070708
epoch: 27.87878787878788


2024-09-03 13:13:13,580 - INFO - Step: 64600
loss: 0.0009
grad_norm: 0.006852076854556799
learning_rate: 0.0010678210678210678
epoch: 27.965367965367964


2024-09-03 13:17:27,587 - INFO - Step: 64680
eval_loss: 0.0021869216579943895
eval_runtime: 190.551
eval_samples_per_second: 498.738
eval_steps_per_second: 2.598
epoch: 28.0


2024-09-03 13:19:02,174 - INFO - Step: 64800
loss: 0.0008
grad_norm: 0.00795813463628292
learning_rate: 0.0010649350649350648
epoch: 28.051948051948052


2024-09-03 13:21:40,999 - INFO - Step: 65000
loss: 0.0008
grad_norm: 0.0050737615674734116
learning_rate: 0.001062049062049062
epoch: 28.138528138528137


2024-09-03 13:24:21,232 - INFO - Step: 65200
loss: 0.0008
grad_norm: 0.007335213478654623
learning_rate: 0.0010591630591630591
epoch: 28.225108225108226


2024-09-03 13:27:00,401 - INFO - Step: 65400
loss: 0.0008
grad_norm: 0.004920414183288813
learning_rate: 0.0010562770562770564
epoch: 28.31168831168831


2024-09-03 13:29:39,885 - INFO - Step: 65600
loss: 0.0008
grad_norm: 0.007421863730996847
learning_rate: 0.0010533910533910534
epoch: 28.3982683982684


2024-09-03 13:32:18,730 - INFO - Step: 65800
loss: 0.0009
grad_norm: 0.024099459871649742
learning_rate: 0.0010505050505050506
epoch: 28.484848484848484


2024-09-03 13:34:57,786 - INFO - Step: 66000
loss: 0.0009
grad_norm: 0.003627537749707699
learning_rate: 0.0010476190476190477
epoch: 28.571428571428573


2024-09-03 13:37:37,689 - INFO - Step: 66200
loss: 0.0009
grad_norm: 0.0032843388617038727
learning_rate: 0.0010447330447330447
epoch: 28.658008658008658


2024-09-03 13:40:16,924 - INFO - Step: 66400
loss: 0.0009
grad_norm: 0.007552403956651688
learning_rate: 0.0010418470418470417
epoch: 28.744588744588743


2024-09-03 13:42:57,051 - INFO - Step: 66600
loss: 0.0009
grad_norm: 0.00496134115383029
learning_rate: 0.001038961038961039
epoch: 28.83116883116883


2024-09-03 13:45:35,805 - INFO - Step: 66800
loss: 0.0009
grad_norm: 0.005235955584794283
learning_rate: 0.0010360750360750362
epoch: 28.917748917748916


2024-09-03 13:51:17,176 - INFO - Step: 66990
eval_loss: 0.0021536981221288443
eval_runtime: 190.7642
eval_samples_per_second: 498.181
eval_steps_per_second: 2.595
epoch: 29.0


2024-09-03 13:51:24,969 - INFO - Step: 67000
loss: 0.0009
grad_norm: 0.002583967288956046
learning_rate: 0.0010331890331890332
epoch: 29.004329004329005


2024-09-03 13:54:04,017 - INFO - Step: 67200
loss: 0.0007
grad_norm: 0.00599159300327301
learning_rate: 0.0010303030303030303
epoch: 29.09090909090909


2024-09-03 13:56:42,537 - INFO - Step: 67400
loss: 0.0007
grad_norm: 0.00379116740077734
learning_rate: 0.0010274170274170273
epoch: 29.17748917748918


2024-09-03 13:59:21,964 - INFO - Step: 67600
loss: 0.0008
grad_norm: 0.006904610898345709
learning_rate: 0.0010245310245310247
epoch: 29.264069264069263


2024-09-03 14:01:59,882 - INFO - Step: 67800
loss: 0.0008
grad_norm: 0.005758820567280054
learning_rate: 0.0010216450216450218
epoch: 29.350649350649352


2024-09-03 14:04:37,381 - INFO - Step: 68000
loss: 0.0008
grad_norm: 0.004702810198068619
learning_rate: 0.0010187590187590188
epoch: 29.437229437229437


2024-09-03 14:07:16,177 - INFO - Step: 68200
loss: 0.0008
grad_norm: 0.005114683415740728
learning_rate: 0.0010158730158730158
epoch: 29.523809523809526


2024-09-03 14:09:54,511 - INFO - Step: 68400
loss: 0.0008
grad_norm: 0.004333652555942535
learning_rate: 0.0010129870129870129
epoch: 29.61038961038961


2024-09-03 14:12:33,649 - INFO - Step: 68600
loss: 0.0008
grad_norm: 0.005901689175516367
learning_rate: 0.00101010101010101
epoch: 29.696969696969695


2024-09-03 14:15:11,694 - INFO - Step: 68800
loss: 0.0009
grad_norm: 0.003804505104199052
learning_rate: 0.0010072150072150073
epoch: 29.783549783549784


2024-09-03 14:17:50,276 - INFO - Step: 69000
loss: 0.0008
grad_norm: 0.005017750896513462
learning_rate: 0.0010043290043290044
epoch: 29.87012987012987


2024-09-03 14:20:30,078 - INFO - Step: 69200
loss: 0.0008
grad_norm: 0.007251797243952751
learning_rate: 0.0010014430014430014
epoch: 29.956709956709958


2024-09-03 14:25:00,098 - INFO - Step: 69300
eval_loss: 0.0021573833655565977
eval_runtime: 190.82
eval_samples_per_second: 498.035
eval_steps_per_second: 2.594
epoch: 30.0


2024-09-03 14:26:19,139 - INFO - Step: 69400
loss: 0.0007
grad_norm: 0.007089712657034397
learning_rate: 0.0009985569985569986
epoch: 30.043290043290042


2024-09-03 14:28:59,167 - INFO - Step: 69600
loss: 0.0007
grad_norm: 0.003506347304210067
learning_rate: 0.0009956709956709957
epoch: 30.12987012987013


2024-09-03 14:31:37,241 - INFO - Step: 69800
loss: 0.0007
grad_norm: 0.0039025305304676294
learning_rate: 0.0009927849927849927
epoch: 30.216450216450216


2024-09-03 14:34:15,883 - INFO - Step: 70000
loss: 0.0007
grad_norm: 0.006496675778180361
learning_rate: 0.00098989898989899
epoch: 30.303030303030305


2024-09-03 14:36:55,667 - INFO - Step: 70200
loss: 0.0008
grad_norm: 0.003865598700940609
learning_rate: 0.000987012987012987
epoch: 30.38961038961039


2024-09-03 14:39:34,488 - INFO - Step: 70400
loss: 0.0008
grad_norm: 0.002525195013731718
learning_rate: 0.000984126984126984
epoch: 30.476190476190474


2024-09-03 14:42:14,020 - INFO - Step: 70600
loss: 0.0008
grad_norm: 0.005316511262208223
learning_rate: 0.0009812409812409812
epoch: 30.562770562770563


2024-09-03 14:44:53,450 - INFO - Step: 70800
loss: 0.0008
grad_norm: 0.00410895561799407
learning_rate: 0.0009783549783549783
epoch: 30.649350649350648


2024-09-03 14:47:33,159 - INFO - Step: 71000
loss: 0.0007
grad_norm: 0.015360860154032707
learning_rate: 0.0009754689754689755
epoch: 30.735930735930737


2024-09-03 14:50:13,787 - INFO - Step: 71200
loss: 0.0008
grad_norm: 0.007040862459689379
learning_rate: 0.0009725829725829725
epoch: 30.82251082251082


2024-09-03 14:52:53,360 - INFO - Step: 71400
loss: 0.0008
grad_norm: 0.003933811094611883
learning_rate: 0.0009696969696969698
epoch: 30.90909090909091


2024-09-03 14:55:33,507 - INFO - Step: 71600
loss: 0.0008
grad_norm: 0.0061783259734511375
learning_rate: 0.0009668109668109668
epoch: 30.995670995670995


2024-09-03 14:58:52,843 - INFO - Step: 71610
eval_loss: 0.002300818683579564
eval_runtime: 191.5783
eval_samples_per_second: 496.064
eval_steps_per_second: 2.584
epoch: 31.0


2024-09-03 15:01:23,814 - INFO - Step: 71800
loss: 0.0007
grad_norm: 0.005258024670183659
learning_rate: 0.000963924963924964
epoch: 31.082251082251084


2024-09-03 15:04:03,344 - INFO - Step: 72000
loss: 0.0007
grad_norm: 0.0032480221707373857
learning_rate: 0.0009610389610389611
epoch: 31.16883116883117


2024-09-03 15:06:43,916 - INFO - Step: 72200
loss: 0.0007
grad_norm: 0.006202578544616699
learning_rate: 0.0009581529581529582
epoch: 31.255411255411257


2024-09-03 15:09:23,300 - INFO - Step: 72400
loss: 0.0007
grad_norm: 0.0064794099889695644
learning_rate: 0.0009552669552669552
epoch: 31.341991341991342


2024-09-03 15:12:03,647 - INFO - Step: 72600
loss: 0.0007
grad_norm: 0.007358339615166187
learning_rate: 0.0009523809523809524
epoch: 31.428571428571427


2024-09-03 15:14:43,180 - INFO - Step: 72800
loss: 0.0007
grad_norm: 0.011488338932394981
learning_rate: 0.0009494949494949495
epoch: 31.515151515151516


2024-09-03 15:17:22,713 - INFO - Step: 73000
loss: 0.001
grad_norm: 0.006414588075131178
learning_rate: 0.0009466089466089465
epoch: 31.6017316017316


2024-09-03 15:20:03,391 - INFO - Step: 73200
loss: 0.0008
grad_norm: 0.002673220122233033
learning_rate: 0.0009437229437229438
epoch: 31.68831168831169


2024-09-03 15:22:43,209 - INFO - Step: 73400
loss: 0.0007
grad_norm: 0.005090709775686264
learning_rate: 0.0009408369408369408
epoch: 31.774891774891774


2024-09-03 15:25:23,988 - INFO - Step: 73600
loss: 0.0007
grad_norm: 0.004421599209308624
learning_rate: 0.000937950937950938
epoch: 31.861471861471863


2024-09-03 15:28:03,339 - INFO - Step: 73800
loss: 0.0007
grad_norm: 0.0036172415129840374
learning_rate: 0.0009350649350649351
epoch: 31.948051948051948


2024-09-03 15:32:51,511 - INFO - Step: 73920
eval_loss: 0.0022408536169677973
eval_runtime: 192.4351
eval_samples_per_second: 493.855
eval_steps_per_second: 2.572
epoch: 32.0


2024-09-03 15:33:55,060 - INFO - Step: 74000
loss: 0.0007
grad_norm: 0.002925189910456538
learning_rate: 0.0009321789321789322
epoch: 32.03463203463203


2024-09-03 15:36:36,042 - INFO - Step: 74200
loss: 0.0006
grad_norm: 0.005575235467404127
learning_rate: 0.0009292929292929292
epoch: 32.121212121212125


2024-09-03 15:39:16,056 - INFO - Step: 74400
loss: 0.0006
grad_norm: 0.004273428115993738
learning_rate: 0.0009264069264069265
epoch: 32.20779220779221


2024-09-03 15:41:56,803 - INFO - Step: 74600
loss: 0.0006
grad_norm: 0.003886764170601964
learning_rate: 0.0009235209235209235
epoch: 32.294372294372295


2024-09-03 15:44:36,713 - INFO - Step: 74800
loss: 0.0006
grad_norm: 0.003100576112046838
learning_rate: 0.0009206349206349207
epoch: 32.38095238095238


2024-09-03 15:47:16,617 - INFO - Step: 75000
loss: 0.0007
grad_norm: 0.0087248794734478
learning_rate: 0.0009177489177489178
epoch: 32.467532467532465


2024-09-03 15:49:57,382 - INFO - Step: 75200
loss: 0.0006
grad_norm: 0.004604896530508995
learning_rate: 0.0009148629148629148
epoch: 32.55411255411256


2024-09-03 15:52:37,757 - INFO - Step: 75400
loss: 0.0007
grad_norm: 0.006125580053776503
learning_rate: 0.0009119769119769121
epoch: 32.64069264069264


2024-09-03 15:55:18,532 - INFO - Step: 75600
loss: 0.0007
grad_norm: 0.00514303520321846
learning_rate: 0.0009090909090909091
epoch: 32.72727272727273


2024-09-03 15:57:58,493 - INFO - Step: 75800
loss: 0.0008
grad_norm: 0.003807174740359187
learning_rate: 0.0009062049062049062
epoch: 32.81385281385281


2024-09-03 16:00:38,016 - INFO - Step: 76000
loss: 0.0008
grad_norm: 0.004602545406669378
learning_rate: 0.0009033189033189034
epoch: 32.900432900432904


2024-09-03 16:03:18,611 - INFO - Step: 76200
loss: 0.0008
grad_norm: 0.004075833596289158
learning_rate: 0.0009004329004329005
epoch: 32.98701298701299


2024-09-03 16:06:54,451 - INFO - Step: 76230
eval_loss: 0.0022325548343360424
eval_runtime: 191.9298
eval_samples_per_second: 495.155
eval_steps_per_second: 2.579
epoch: 33.0


2024-09-03 16:09:09,301 - INFO - Step: 76400
loss: 0.0006
grad_norm: 0.00119685847312212
learning_rate: 0.0008975468975468975
epoch: 33.073593073593074


2024-09-03 16:11:49,732 - INFO - Step: 76600
loss: 0.0005
grad_norm: 0.006144025828689337
learning_rate: 0.0008946608946608948
epoch: 33.16017316017316


2024-09-03 16:14:28,474 - INFO - Step: 76800
loss: 0.0006
grad_norm: 0.003814626019448042
learning_rate: 0.0008917748917748918
epoch: 33.246753246753244


2024-09-03 16:17:06,747 - INFO - Step: 77000
loss: 0.0006
grad_norm: 0.0038711591623723507
learning_rate: 0.0008888888888888888
epoch: 33.333333333333336


2024-09-03 16:19:46,036 - INFO - Step: 77200
loss: 0.0006
grad_norm: 0.007972024381160736
learning_rate: 0.0008860028860028861
epoch: 33.41991341991342


2024-09-03 16:22:24,439 - INFO - Step: 77400
loss: 0.0006
grad_norm: 0.00454507814720273
learning_rate: 0.0008831168831168831
epoch: 33.506493506493506


2024-09-03 16:25:04,934 - INFO - Step: 77600
loss: 0.0007
grad_norm: 0.005161195062100887
learning_rate: 0.0008802308802308802
epoch: 33.59307359307359


2024-09-03 16:27:43,782 - INFO - Step: 77800
loss: 0.0007
grad_norm: 0.003578552510589361
learning_rate: 0.0008773448773448774
epoch: 33.67965367965368


2024-09-03 16:30:22,448 - INFO - Step: 78000
loss: 0.0007
grad_norm: 0.003446982242166996
learning_rate: 0.0008744588744588745
epoch: 33.76623376623377


2024-09-03 16:33:02,002 - INFO - Step: 78200
loss: 0.0007
grad_norm: 0.008087212219834328
learning_rate: 0.0008715728715728715
epoch: 33.85281385281385


2024-09-03 16:35:40,846 - INFO - Step: 78400
loss: 0.0007
grad_norm: 0.006165637634694576
learning_rate: 0.0008686868686868688
epoch: 33.93939393939394


2024-09-03 16:40:45,506 - INFO - Step: 78540
eval_loss: 0.0022941932547837496
eval_runtime: 192.2389
eval_samples_per_second: 494.359
eval_steps_per_second: 2.575
epoch: 34.0


2024-09-03 16:41:33,112 - INFO - Step: 78600
loss: 0.0006
grad_norm: 0.0054105487652122974
learning_rate: 0.0008658008658008658
epoch: 34.02597402597402


2024-09-03 16:44:12,477 - INFO - Step: 78800
loss: 0.0005
grad_norm: 0.003561889287084341
learning_rate: 0.0008629148629148629
epoch: 34.112554112554115


2024-09-03 16:46:51,129 - INFO - Step: 79000
loss: 0.0005
grad_norm: 0.00455392524600029
learning_rate: 0.0008600288600288601
epoch: 34.1991341991342


2024-09-03 16:49:31,236 - INFO - Step: 79200
loss: 0.0006
grad_norm: 0.004245544783771038
learning_rate: 0.0008571428571428571
epoch: 34.285714285714285


2024-09-03 16:52:09,976 - INFO - Step: 79400
loss: 0.0006
grad_norm: 0.003936082124710083
learning_rate: 0.0008542568542568542
epoch: 34.37229437229437


2024-09-03 16:54:49,461 - INFO - Step: 79600
loss: 0.0006
grad_norm: 0.006341239903122187
learning_rate: 0.0008513708513708514
epoch: 34.45887445887446


2024-09-03 16:57:28,052 - INFO - Step: 79800
loss: 0.0006
grad_norm: 0.0068284012377262115
learning_rate: 0.0008484848484848485
epoch: 34.54545454545455


2024-09-03 17:00:07,160 - INFO - Step: 80000
loss: 0.0006
grad_norm: 0.003519610036164522
learning_rate: 0.0008455988455988456
epoch: 34.63203463203463


2024-09-03 17:02:47,059 - INFO - Step: 80200
loss: 0.0007
grad_norm: 0.004720211029052734
learning_rate: 0.0008427128427128428
epoch: 34.71861471861472


2024-09-03 17:05:26,020 - INFO - Step: 80400
loss: 0.0006
grad_norm: 0.005450631026178598
learning_rate: 0.0008398268398268398
epoch: 34.8051948051948


2024-09-03 17:08:05,549 - INFO - Step: 80600
loss: 0.0006
grad_norm: 0.0036365361884236336
learning_rate: 0.000836940836940837
epoch: 34.891774891774894


2024-09-03 17:10:43,889 - INFO - Step: 80800
loss: 0.0006
grad_norm: 0.0033839165698736906
learning_rate: 0.0008340548340548341
epoch: 34.97835497835498


2024-09-03 17:14:34,896 - INFO - Step: 80850
eval_loss: 0.002406967571005225
eval_runtime: 191.5228
eval_samples_per_second: 496.207
eval_steps_per_second: 2.585
epoch: 35.0


2024-09-03 17:16:33,347 - INFO - Step: 81000
loss: 0.0006
grad_norm: 0.005805291701108217
learning_rate: 0.0008311688311688312
epoch: 35.064935064935064


2024-09-03 17:19:12,610 - INFO - Step: 81200
loss: 0.0006
grad_norm: 0.004249191842973232
learning_rate: 0.0008282828282828283
epoch: 35.15151515151515


2024-09-03 17:21:50,575 - INFO - Step: 81400
loss: 0.0005
grad_norm: 0.004816142842173576
learning_rate: 0.0008253968253968254
epoch: 35.23809523809524


2024-09-03 17:24:29,774 - INFO - Step: 81600
loss: 0.0006
grad_norm: 0.004975981544703245
learning_rate: 0.0008225108225108225
epoch: 35.324675324675326


2024-09-03 17:27:07,953 - INFO - Step: 81800
loss: 0.0006
grad_norm: 0.0029958002269268036
learning_rate: 0.0008196248196248196
epoch: 35.41125541125541


2024-09-03 17:29:46,318 - INFO - Step: 82000
loss: 0.0006
grad_norm: 0.007284069433808327
learning_rate: 0.0008167388167388168
epoch: 35.497835497835496


2024-09-03 17:32:25,985 - INFO - Step: 82200
loss: 0.0006
grad_norm: 0.0041112289763987064
learning_rate: 0.0008138528138528138
epoch: 35.58441558441559


2024-09-03 17:35:04,585 - INFO - Step: 82400
loss: 0.0006
grad_norm: 0.004227177705615759
learning_rate: 0.000810966810966811
epoch: 35.67099567099567


2024-09-03 17:37:44,421 - INFO - Step: 82600
loss: 0.0006
grad_norm: 0.005250651389360428
learning_rate: 0.0008080808080808081
epoch: 35.75757575757576


2024-09-03 17:40:23,614 - INFO - Step: 82800
loss: 0.0006
grad_norm: 0.0026464720722287893
learning_rate: 0.0008051948051948052
epoch: 35.84415584415584


2024-09-03 17:43:02,552 - INFO - Step: 83000
loss: 0.0006
grad_norm: 0.004373724572360516
learning_rate: 0.0008023088023088024
epoch: 35.93073593073593


2024-09-03 17:48:22,284 - INFO - Step: 83160
eval_loss: 0.002493886509910226
eval_runtime: 191.6124
eval_samples_per_second: 495.975
eval_steps_per_second: 2.583
epoch: 36.0


2024-09-03 17:48:53,773 - INFO - Step: 83200
loss: 0.0006
grad_norm: 0.004552027676254511
learning_rate: 0.0007994227994227994
epoch: 36.01731601731602


2024-09-03 17:51:32,879 - INFO - Step: 83400
loss: 0.0005
grad_norm: 0.0040135798044502735
learning_rate: 0.0007965367965367965
epoch: 36.103896103896105


2024-09-03 17:54:12,727 - INFO - Step: 83600
loss: 0.0005
grad_norm: 0.004737126175314188
learning_rate: 0.0007936507936507937
epoch: 36.19047619047619


2024-09-03 17:56:51,763 - INFO - Step: 83800
loss: 0.0005
grad_norm: 0.003342827782034874
learning_rate: 0.0007907647907647908
epoch: 36.277056277056275


2024-09-03 17:59:30,952 - INFO - Step: 84000
loss: 0.0006
grad_norm: 0.001954165520146489
learning_rate: 0.0007878787878787878
epoch: 36.36363636363637


2024-09-03 18:02:11,018 - INFO - Step: 84200
loss: 0.0005
grad_norm: 0.0026617657858878374
learning_rate: 0.0007849927849927851
epoch: 36.45021645021645


2024-09-03 18:04:50,214 - INFO - Step: 84400
loss: 0.0006
grad_norm: 0.0047556147910654545
learning_rate: 0.0007821067821067821
epoch: 36.53679653679654


2024-09-03 18:07:30,115 - INFO - Step: 84600
loss: 0.0006
grad_norm: 0.007491475436836481
learning_rate: 0.0007792207792207793
epoch: 36.62337662337662


2024-09-03 18:10:08,702 - INFO - Step: 84800
loss: 0.0005
grad_norm: 0.004240796901285648
learning_rate: 0.0007763347763347764
epoch: 36.70995670995671


2024-09-03 18:12:47,737 - INFO - Step: 85000
loss: 0.0006
grad_norm: 0.00692940317094326
learning_rate: 0.0007734487734487735
epoch: 36.7965367965368


2024-09-03 18:15:27,844 - INFO - Step: 85200
loss: 0.0006
grad_norm: 0.004264392424374819
learning_rate: 0.0007705627705627706
epoch: 36.883116883116884


2024-09-03 18:18:06,733 - INFO - Step: 85400
loss: 0.0006
grad_norm: 0.005230213049799204
learning_rate: 0.0007676767676767677
epoch: 36.96969696969697


2024-09-03 18:22:13,903 - INFO - Step: 85470
eval_loss: 0.0024188566021621227
eval_runtime: 191.6613
eval_samples_per_second: 495.849
eval_steps_per_second: 2.583
epoch: 37.0


2024-09-03 18:23:57,785 - INFO - Step: 85600
loss: 0.0005
grad_norm: 0.003733891062438488
learning_rate: 0.0007647907647907648
epoch: 37.056277056277054


2024-09-03 18:26:36,936 - INFO - Step: 85800
loss: 0.0005
grad_norm: 0.00320683466270566
learning_rate: 0.0007619047619047619
epoch: 37.142857142857146


2024-09-03 18:29:16,041 - INFO - Step: 86000
loss: 0.0005
grad_norm: 0.004688235465437174
learning_rate: 0.0007590187590187591
epoch: 37.22943722943723


2024-09-03 18:31:56,410 - INFO - Step: 86200
loss: 0.0005
grad_norm: 0.003214565571397543
learning_rate: 0.0007561327561327561
epoch: 37.316017316017316


2024-09-03 18:34:35,344 - INFO - Step: 86400
loss: 0.0005
grad_norm: 0.0032752035185694695
learning_rate: 0.0007532467532467533
epoch: 37.4025974025974


2024-09-03 18:37:14,671 - INFO - Step: 86600
loss: 0.0006
grad_norm: 0.004422643221914768
learning_rate: 0.0007503607503607504
epoch: 37.489177489177486


2024-09-03 18:39:53,643 - INFO - Step: 86800
loss: 0.0006
grad_norm: 0.005282171536237001
learning_rate: 0.0007474747474747475
epoch: 37.57575757575758


2024-09-03 18:42:31,667 - INFO - Step: 87000
loss: 0.0005
grad_norm: 0.004434626083821058
learning_rate: 0.0007445887445887446
epoch: 37.66233766233766


2024-09-03 18:45:10,996 - INFO - Step: 87200
loss: 0.0005
grad_norm: 0.00506642134860158
learning_rate: 0.0007417027417027418
epoch: 37.74891774891775


2024-09-03 18:47:49,465 - INFO - Step: 87400
loss: 0.0006
grad_norm: 0.004062259569764137
learning_rate: 0.0007388167388167388
epoch: 37.83549783549783


2024-09-03 18:50:29,550 - INFO - Step: 87600
loss: 0.0006
grad_norm: 0.005990787409245968
learning_rate: 0.0007359307359307359
epoch: 37.922077922077925


2024-09-03 18:56:04,232 - INFO - Step: 87780
eval_loss: 0.0024935295805335045
eval_runtime: 191.5663
eval_samples_per_second: 496.095
eval_steps_per_second: 2.584
epoch: 38.0


2024-09-03 18:56:19,975 - INFO - Step: 87800
loss: 0.0005
grad_norm: 0.004131897818297148
learning_rate: 0.0007330447330447331
epoch: 38.00865800865801


2024-09-03 18:58:58,888 - INFO - Step: 88000
loss: 0.0004
grad_norm: 0.0028930120170116425
learning_rate: 0.0007301587301587301
epoch: 38.095238095238095


2024-09-03 19:01:39,175 - INFO - Step: 88200
loss: 0.0004
grad_norm: 0.007560191210359335
learning_rate: 0.0007272727272727273
epoch: 38.18181818181818


2024-09-03 19:04:18,279 - INFO - Step: 88400
loss: 0.0005
grad_norm: 0.0023786055389791727
learning_rate: 0.0007243867243867244
epoch: 38.26839826839827


2024-09-03 19:06:57,950 - INFO - Step: 88600
loss: 0.0005
grad_norm: 0.005295298062264919
learning_rate: 0.0007215007215007215
epoch: 38.35497835497836


2024-09-03 19:09:36,905 - INFO - Step: 88800
loss: 0.0005
grad_norm: 0.004881769418716431
learning_rate: 0.0007186147186147186
epoch: 38.44155844155844


2024-09-03 19:12:15,739 - INFO - Step: 89000
loss: 0.0005
grad_norm: 0.0036770510487258434
learning_rate: 0.0007157287157287158
epoch: 38.52813852813853


2024-09-03 19:14:55,287 - INFO - Step: 89200
loss: 0.0005
grad_norm: 0.008441705256700516
learning_rate: 0.0007128427128427128
epoch: 38.61471861471861


2024-09-03 19:17:33,776 - INFO - Step: 89400
loss: 0.0005
grad_norm: 0.005700343754142523
learning_rate: 0.00070995670995671
epoch: 38.701298701298704


2024-09-03 19:20:13,349 - INFO - Step: 89600
loss: 0.0005
grad_norm: 0.004287720657885075
learning_rate: 0.0007070707070707071
epoch: 38.78787878787879


2024-09-03 19:22:51,982 - INFO - Step: 89800
loss: 0.0005
grad_norm: 0.0028637712821364403
learning_rate: 0.0007041847041847041
epoch: 38.874458874458874


2024-09-03 19:25:30,291 - INFO - Step: 90000
loss: 0.0005
grad_norm: 0.005751830991357565
learning_rate: 0.0007012987012987013
epoch: 38.96103896103896


2024-09-03 19:29:53,812 - INFO - Step: 90090
eval_loss: 0.0024818861857056618
eval_runtime: 191.2409
eval_samples_per_second: 496.939
eval_steps_per_second: 2.588
epoch: 39.0


2024-09-03 19:31:20,563 - INFO - Step: 90200
loss: 0.0005
grad_norm: 0.0046717096120119095
learning_rate: 0.0006984126984126984
epoch: 39.04761904761905


2024-09-03 19:33:59,278 - INFO - Step: 90400
loss: 0.0004
grad_norm: 0.0015755564672872424
learning_rate: 0.0006955266955266956
epoch: 39.134199134199136


2024-09-03 19:36:38,494 - INFO - Step: 90600
loss: 0.0004
grad_norm: 0.006202239543199539
learning_rate: 0.0006926406926406926
epoch: 39.22077922077922


2024-09-03 19:39:16,845 - INFO - Step: 90800
loss: 0.0005
grad_norm: 0.0047246916219592094
learning_rate: 0.0006897546897546898
epoch: 39.307359307359306


2024-09-03 19:41:54,913 - INFO - Step: 91000
loss: 0.0005
grad_norm: 0.005069202743470669
learning_rate: 0.0006868686868686869
epoch: 39.39393939393939


2024-09-03 19:44:34,105 - INFO - Step: 91200
loss: 0.0005
grad_norm: 0.003960005473345518
learning_rate: 0.000683982683982684
epoch: 39.48051948051948


2024-09-03 19:47:12,585 - INFO - Step: 91400
loss: 0.0004
grad_norm: 0.0025696614757180214
learning_rate: 0.0006810966810966811
epoch: 39.56709956709957


2024-09-03 19:49:52,681 - INFO - Step: 91600
loss: 0.0005
grad_norm: 0.005678722634911537
learning_rate: 0.0006782106782106783
epoch: 39.65367965367965


2024-09-03 19:52:31,670 - INFO - Step: 91800
loss: 0.0005
grad_norm: 0.004013177007436752
learning_rate: 0.0006753246753246753
epoch: 39.74025974025974


2024-09-03 19:55:11,000 - INFO - Step: 92000
loss: 0.0005
grad_norm: 0.005083736032247543
learning_rate: 0.0006724386724386724
epoch: 39.82683982683983


2024-09-03 19:57:51,192 - INFO - Step: 92200
loss: 0.0005
grad_norm: 0.004742222838103771
learning_rate: 0.0006695526695526696
epoch: 39.913419913419915


2024-09-03 20:00:30,010 - INFO - Step: 92400
loss: 0.0005
grad_norm: 0.001977965235710144
learning_rate: 0.0006666666666666666
epoch: 40.0


2024-09-03 20:03:41,385 - INFO - Step: 92400
eval_loss: 0.002643642947077751
eval_runtime: 191.3733
eval_samples_per_second: 496.595
eval_steps_per_second: 2.587
epoch: 40.0


2024-09-03 20:06:21,031 - INFO - Step: 92600
loss: 0.0004
grad_norm: 0.006387933623045683
learning_rate: 0.0006637806637806638
epoch: 40.086580086580085


2024-09-03 20:09:00,239 - INFO - Step: 92800
loss: 0.0004
grad_norm: 0.0011362119112163782
learning_rate: 0.0006608946608946609
epoch: 40.17316017316017


2024-09-03 20:11:38,761 - INFO - Step: 93000
loss: 0.0004
grad_norm: 0.0024234058801084757
learning_rate: 0.000658008658008658
epoch: 40.25974025974026


2024-09-03 20:14:18,816 - INFO - Step: 93200
loss: 0.0004
grad_norm: 0.004128213971853256
learning_rate: 0.0006551226551226551
epoch: 40.34632034632035


2024-09-03 20:16:57,141 - INFO - Step: 93400
loss: 0.0004
grad_norm: 0.004026970826089382
learning_rate: 0.0006522366522366523
epoch: 40.43290043290043


2024-09-03 20:19:36,375 - INFO - Step: 93600
loss: 0.0004
grad_norm: 0.00353227648884058
learning_rate: 0.0006493506493506494
epoch: 40.51948051948052


2024-09-03 20:22:15,125 - INFO - Step: 93800
loss: 0.0004
grad_norm: 0.00160226970911026
learning_rate: 0.0006464646464646465
epoch: 40.60606060606061


2024-09-03 20:24:53,795 - INFO - Step: 94000
loss: 0.0004
grad_norm: 0.00631833728402853
learning_rate: 0.0006435786435786436
epoch: 40.692640692640694


2024-09-03 20:27:33,595 - INFO - Step: 94200
loss: 0.0004
grad_norm: 0.004400286823511124
learning_rate: 0.0006406926406926406
epoch: 40.77922077922078


2024-09-03 20:30:12,732 - INFO - Step: 94400
loss: 0.0004
grad_norm: 0.006600474938750267
learning_rate: 0.0006378066378066378
epoch: 40.865800865800864


2024-09-03 20:32:52,639 - INFO - Step: 94600
loss: 0.0004
grad_norm: 0.004474223591387272
learning_rate: 0.0006349206349206349
epoch: 40.95238095238095


2024-09-03 20:37:31,172 - INFO - Step: 94710
eval_loss: 0.0027144537307322025
eval_runtime: 191.3348
eval_samples_per_second: 496.695
eval_steps_per_second: 2.587
epoch: 41.0


2024-09-03 20:38:42,210 - INFO - Step: 94800
loss: 0.0004
grad_norm: 0.0035574010107666254
learning_rate: 0.0006320346320346321
epoch: 41.03896103896104


2024-09-03 20:41:21,514 - INFO - Step: 95000
loss: 0.0003
grad_norm: 0.001343805924989283
learning_rate: 0.0006291486291486291
epoch: 41.125541125541126


2024-09-03 20:44:01,168 - INFO - Step: 95200
loss: 0.0004
grad_norm: 0.004475378431379795
learning_rate: 0.0006262626262626263
epoch: 41.21212121212121


2024-09-03 20:46:40,153 - INFO - Step: 95400
loss: 0.0004
grad_norm: 0.0033758345525711775
learning_rate: 0.0006233766233766234
epoch: 41.298701298701296


2024-09-03 20:49:19,784 - INFO - Step: 95600
loss: 0.0004
grad_norm: 0.00266036344692111
learning_rate: 0.0006204906204906206
epoch: 41.38528138528139


2024-09-03 20:51:58,620 - INFO - Step: 95800
loss: 0.0004
grad_norm: 0.00459558330476284
learning_rate: 0.0006176046176046176
epoch: 41.47186147186147


2024-09-03 20:54:37,445 - INFO - Step: 96000
loss: 0.0004
grad_norm: 0.0031617330387234688
learning_rate: 0.0006147186147186147
epoch: 41.55844155844156


2024-09-03 20:57:17,332 - INFO - Step: 96200
loss: 0.0004
grad_norm: 0.0033629804383963346
learning_rate: 0.0006118326118326119
epoch: 41.64502164502164


2024-09-03 20:59:55,943 - INFO - Step: 96400
loss: 0.0004
grad_norm: 0.003311432432383299
learning_rate: 0.0006089466089466089
epoch: 41.73160173160173


2024-09-03 21:02:34,967 - INFO - Step: 96600
loss: 0.0004
grad_norm: 0.004843283444643021
learning_rate: 0.0006060606060606061
epoch: 41.81818181818182


2024-09-03 21:05:12,982 - INFO - Step: 96800
loss: 0.0004
grad_norm: 0.002634307835251093
learning_rate: 0.0006031746031746032
epoch: 41.904761904761905


2024-09-03 21:07:50,792 - INFO - Step: 97000
loss: 0.0005
grad_norm: 0.0047485060058534145
learning_rate: 0.0006002886002886003
epoch: 41.99134199134199


2024-09-03 21:11:19,216 - INFO - Step: 97020
eval_loss: 0.002700829179957509
eval_runtime: 191.5863
eval_samples_per_second: 496.043
eval_steps_per_second: 2.584
epoch: 42.0


2024-09-03 21:13:41,964 - INFO - Step: 97200
loss: 0.0003
grad_norm: 0.0022605154663324356
learning_rate: 0.0005974025974025974
epoch: 42.077922077922075


2024-09-03 21:16:21,204 - INFO - Step: 97400
loss: 0.0003
grad_norm: 0.003467999631538987
learning_rate: 0.0005945165945165946
epoch: 42.16450216450217


2024-09-03 21:19:01,311 - INFO - Step: 97600
loss: 0.0004
grad_norm: 0.003546117339283228
learning_rate: 0.0005916305916305916
epoch: 42.25108225108225


2024-09-03 21:21:40,474 - INFO - Step: 97800
loss: 0.0004
grad_norm: 0.005103747360408306
learning_rate: 0.0005887445887445888
epoch: 42.33766233766234


2024-09-03 21:24:19,802 - INFO - Step: 98000
loss: 0.0004
grad_norm: 0.003493936499580741
learning_rate: 0.0005858585858585859
epoch: 42.42424242424242


2024-09-03 21:26:59,277 - INFO - Step: 98200
loss: 0.0004
grad_norm: 0.004810646641999483
learning_rate: 0.0005829725829725829
epoch: 42.510822510822514


2024-09-03 21:29:38,377 - INFO - Step: 98400
loss: 0.0004
grad_norm: 0.0029713502153754234
learning_rate: 0.0005800865800865801
epoch: 42.5974025974026


2024-09-03 21:32:18,245 - INFO - Step: 98600
loss: 0.0004
grad_norm: 0.0028497232124209404
learning_rate: 0.0005772005772005772
epoch: 42.683982683982684


2024-09-03 21:34:57,216 - INFO - Step: 98800
loss: 0.0004
grad_norm: 0.0027098702266812325
learning_rate: 0.0005743145743145743
epoch: 42.77056277056277


2024-09-03 21:37:36,323 - INFO - Step: 99000
loss: 0.0004
grad_norm: 0.006202098913490772
learning_rate: 0.0005714285714285714
epoch: 42.857142857142854


2024-09-03 21:40:16,426 - INFO - Step: 99200
loss: 0.0004
grad_norm: 0.005006285849958658
learning_rate: 0.0005685425685425686
epoch: 42.943722943722946


2024-09-03 21:45:11,454 - INFO - Step: 99330
eval_loss: 0.0028225835412740707
eval_runtime: 191.8606
eval_samples_per_second: 495.333
eval_steps_per_second: 2.58
epoch: 43.0


2024-09-03 21:46:06,360 - INFO - Step: 99400
loss: 0.0004
grad_norm: 0.003063349984586239
learning_rate: 0.0005656565656565656
epoch: 43.03030303030303


2024-09-03 21:48:46,370 - INFO - Step: 99600
loss: 0.0003
grad_norm: 0.0017775915330275893
learning_rate: 0.0005627705627705628
epoch: 43.116883116883116


2024-09-03 21:51:25,661 - INFO - Step: 99800
loss: 0.0003
grad_norm: 0.004586940631270409
learning_rate: 0.0005598845598845599
epoch: 43.2034632034632


2024-09-03 21:54:04,647 - INFO - Step: 100000
loss: 0.0003
grad_norm: 0.0015871495706960559
learning_rate: 0.000556998556998557
epoch: 43.29004329004329


2024-09-03 21:56:44,596 - INFO - Step: 100200
loss: 0.0003
grad_norm: 0.002252544043585658
learning_rate: 0.0005541125541125542
epoch: 43.37662337662338


2024-09-03 21:59:23,766 - INFO - Step: 100400
loss: 0.0003
grad_norm: 0.006143833044916391
learning_rate: 0.0005512265512265512
epoch: 43.46320346320346


2024-09-03 22:02:03,448 - INFO - Step: 100600
loss: 0.0004
grad_norm: 0.003714978462085128
learning_rate: 0.0005483405483405483
epoch: 43.54978354978355


2024-09-03 22:04:42,147 - INFO - Step: 100800
loss: 0.0003
grad_norm: 0.0031498356256633997
learning_rate: 0.0005454545454545455
epoch: 43.63636363636363


2024-09-03 22:07:20,524 - INFO - Step: 101000
loss: 0.0004
grad_norm: 0.004575973842293024
learning_rate: 0.0005425685425685426
epoch: 43.722943722943725


2024-09-03 22:09:59,971 - INFO - Step: 101200
loss: 0.0004
grad_norm: 0.0009206846007145941
learning_rate: 0.0005396825396825396
epoch: 43.80952380952381


2024-09-03 22:12:38,609 - INFO - Step: 101400
loss: 0.0004
grad_norm: 0.0031180831138044596
learning_rate: 0.0005367965367965369
epoch: 43.896103896103895


2024-09-03 22:15:17,706 - INFO - Step: 101600
loss: 0.0004
grad_norm: 0.0032007924746721983
learning_rate: 0.0005339105339105339
epoch: 43.98268398268398


2024-09-03 22:19:01,104 - INFO - Step: 101640
eval_loss: 0.002763052238151431
eval_runtime: 191.8493
eval_samples_per_second: 495.363
eval_steps_per_second: 2.58
epoch: 44.0


2024-09-03 22:21:07,969 - INFO - Step: 101800
loss: 0.0003
grad_norm: 0.0033727395348250866
learning_rate: 0.000531024531024531
epoch: 44.06926406926407


2024-09-03 22:23:47,244 - INFO - Step: 102000
loss: 0.0003
grad_norm: 0.0032862364314496517
learning_rate: 0.0005281385281385282
epoch: 44.15584415584416


2024-09-03 22:26:27,208 - INFO - Step: 102200
loss: 0.0003
grad_norm: 0.0012857683468610048
learning_rate: 0.0005252525252525253
epoch: 44.24242424242424


2024-09-03 22:29:06,055 - INFO - Step: 102400
loss: 0.0003
grad_norm: 0.006077168043702841
learning_rate: 0.0005223665223665223
epoch: 44.32900432900433


2024-09-03 22:31:45,790 - INFO - Step: 102600
loss: 0.0003
grad_norm: 0.002509836805984378
learning_rate: 0.0005194805194805195
epoch: 44.41558441558441


2024-09-03 22:34:24,593 - INFO - Step: 102800
loss: 0.0003
grad_norm: 0.0035930201411247253
learning_rate: 0.0005165945165945166
epoch: 44.502164502164504


2024-09-03 22:37:03,123 - INFO - Step: 103000
loss: 0.0003
grad_norm: 0.005317265167832375
learning_rate: 0.0005137085137085136
epoch: 44.58874458874459


2024-09-03 22:39:43,597 - INFO - Step: 103200
loss: 0.0003
grad_norm: 0.0021762200631201267
learning_rate: 0.0005108225108225109
epoch: 44.675324675324674


2024-09-03 22:42:21,702 - INFO - Step: 103400
loss: 0.0003
grad_norm: 0.0024544710759073496
learning_rate: 0.0005079365079365079
epoch: 44.76190476190476


2024-09-03 22:45:00,829 - INFO - Step: 103600
loss: 0.0003
grad_norm: 0.0024954304099082947
learning_rate: 0.000505050505050505
epoch: 44.84848484848485


2024-09-03 22:47:39,524 - INFO - Step: 103800
loss: 0.0003
grad_norm: 0.006405915133655071
learning_rate: 0.0005021645021645022
epoch: 44.935064935064936


2024-09-03 22:52:50,573 - INFO - Step: 103950
eval_loss: 0.0029140778351575136
eval_runtime: 191.8177
eval_samples_per_second: 495.444
eval_steps_per_second: 2.581
epoch: 45.0


2024-09-03 22:53:29,991 - INFO - Step: 104000
loss: 0.0003
grad_norm: 0.00266676745377481
learning_rate: 0.0004992784992784993
epoch: 45.02164502164502


2024-09-03 22:56:09,782 - INFO - Step: 104200
loss: 0.0003
grad_norm: 0.002006036229431629
learning_rate: 0.0004963924963924963
epoch: 45.108225108225106


2024-09-03 22:58:48,997 - INFO - Step: 104400
loss: 0.0002
grad_norm: 0.0010731753427535295
learning_rate: 0.0004935064935064935
epoch: 45.1948051948052


2024-09-03 23:01:28,806 - INFO - Step: 104600
loss: 0.0003
grad_norm: 0.0040971930138766766
learning_rate: 0.0004906204906204906
epoch: 45.28138528138528


2024-09-03 23:04:07,435 - INFO - Step: 104800
loss: 0.0003
grad_norm: 0.002156989648938179
learning_rate: 0.00048773448773448776
epoch: 45.36796536796537


2024-09-03 23:06:46,772 - INFO - Step: 105000
loss: 0.0003
grad_norm: 0.0008669761009514332
learning_rate: 0.0004848484848484849
epoch: 45.45454545454545


2024-09-03 23:09:26,566 - INFO - Step: 105200
loss: 0.0003
grad_norm: 0.003848432097584009
learning_rate: 0.000481962481962482
epoch: 45.54112554112554


2024-09-03 23:12:05,201 - INFO - Step: 105400
loss: 0.0003
grad_norm: 0.006771830841898918
learning_rate: 0.0004790764790764791
epoch: 45.62770562770563


2024-09-03 23:14:45,611 - INFO - Step: 105600
loss: 0.0003
grad_norm: 0.002853368641808629
learning_rate: 0.0004761904761904762
epoch: 45.714285714285715


2024-09-03 23:17:24,746 - INFO - Step: 105800
loss: 0.0003
grad_norm: 0.0023539753165096045
learning_rate: 0.00047330447330447327
epoch: 45.8008658008658


2024-09-03 23:20:03,884 - INFO - Step: 106000
loss: 0.0003
grad_norm: 0.007150406949222088
learning_rate: 0.0004704184704184704
epoch: 45.887445887445885


2024-09-03 23:22:43,590 - INFO - Step: 106200
loss: 0.0003
grad_norm: 0.0026941720861941576
learning_rate: 0.00046753246753246754
epoch: 45.97402597402598


2024-09-03 23:26:42,867 - INFO - Step: 106260
eval_loss: 0.002917870646342635
eval_runtime: 191.6032
eval_samples_per_second: 495.999
eval_steps_per_second: 2.583
epoch: 46.0


2024-09-03 23:28:33,866 - INFO - Step: 106400
loss: 0.0003
grad_norm: 0.0025270511396229267
learning_rate: 0.0004646464646464646
epoch: 46.06060606060606


2024-09-03 23:31:14,154 - INFO - Step: 106600
loss: 0.0002
grad_norm: 0.0009558909223414958
learning_rate: 0.00046176046176046176
epoch: 46.14718614718615


2024-09-03 23:33:53,885 - INFO - Step: 106800
loss: 0.0003
grad_norm: 0.0036517048720270395
learning_rate: 0.0004588744588744589
epoch: 46.23376623376623


2024-09-03 23:36:33,476 - INFO - Step: 107000
loss: 0.0003
grad_norm: 0.0017389028798788786
learning_rate: 0.00045598845598845603
epoch: 46.32034632034632


2024-09-03 23:39:14,039 - INFO - Step: 107200
loss: 0.0003
grad_norm: 0.005221238825470209
learning_rate: 0.0004531024531024531
epoch: 46.40692640692641


2024-09-03 23:41:52,833 - INFO - Step: 107400
loss: 0.0003
grad_norm: 0.0015492445090785623
learning_rate: 0.00045021645021645025
epoch: 46.493506493506494


2024-09-03 23:44:33,459 - INFO - Step: 107600
loss: 0.0002
grad_norm: 0.003917932976037264
learning_rate: 0.0004473304473304474
epoch: 46.58008658008658


2024-09-03 23:47:13,108 - INFO - Step: 107800
loss: 0.0003
grad_norm: 0.003838862758129835
learning_rate: 0.0004444444444444444
epoch: 46.666666666666664


2024-09-03 23:49:52,742 - INFO - Step: 108000
loss: 0.0003
grad_norm: 0.00262236874550581
learning_rate: 0.00044155844155844155
epoch: 46.753246753246756


2024-09-03 23:52:32,880 - INFO - Step: 108200
loss: 0.0003
grad_norm: 0.002515275962650776
learning_rate: 0.0004386724386724387
epoch: 46.83982683982684


2024-09-03 23:55:11,531 - INFO - Step: 108400
loss: 0.0003
grad_norm: 0.001413549529388547
learning_rate: 0.00043578643578643576
epoch: 46.926406926406926


2024-09-04 00:00:38,978 - INFO - Step: 108570
eval_loss: 0.003031111089512706
eval_runtime: 191.5703
eval_samples_per_second: 496.084
eval_steps_per_second: 2.584
epoch: 47.0


2024-09-04 00:01:02,611 - INFO - Step: 108600
loss: 0.0003
grad_norm: 0.008177049458026886
learning_rate: 0.0004329004329004329
epoch: 47.01298701298701


2024-09-04 00:03:40,933 - INFO - Step: 108800
loss: 0.0002
grad_norm: 0.001007096958346665
learning_rate: 0.00043001443001443004
epoch: 47.099567099567096


2024-09-04 00:06:19,741 - INFO - Step: 109000
loss: 0.0002
grad_norm: 0.01226289477199316
learning_rate: 0.0004271284271284271
epoch: 47.18614718614719


2024-09-04 00:08:59,060 - INFO - Step: 109200
loss: 0.0002
grad_norm: 0.001388759003020823
learning_rate: 0.00042424242424242425
epoch: 47.27272727272727


2024-09-04 00:11:37,560 - INFO - Step: 109400
loss: 0.0002
grad_norm: 0.0026219754945486784
learning_rate: 0.0004213564213564214
epoch: 47.35930735930736


2024-09-04 00:14:17,274 - INFO - Step: 109600
loss: 0.0003
grad_norm: 0.004739636089652777
learning_rate: 0.0004184704184704185
epoch: 47.44588744588744


2024-09-04 00:16:55,981 - INFO - Step: 109800
loss: 0.0002
grad_norm: 0.0015339066740125418
learning_rate: 0.0004155844155844156
epoch: 47.532467532467535


2024-09-04 00:19:34,689 - INFO - Step: 110000
loss: 0.0003
grad_norm: 0.0017692040419206023
learning_rate: 0.0004126984126984127
epoch: 47.61904761904762


2024-09-04 00:22:14,883 - INFO - Step: 110200
loss: 0.0002
grad_norm: 0.0022981564980000257
learning_rate: 0.0004098124098124098
epoch: 47.705627705627705


2024-09-04 00:24:53,855 - INFO - Step: 110400
loss: 0.0003
grad_norm: 0.004477445036172867
learning_rate: 0.0004069264069264069
epoch: 47.79220779220779


2024-09-04 00:27:33,794 - INFO - Step: 110600
loss: 0.0003
grad_norm: 0.0021545307245105505
learning_rate: 0.00040404040404040404
epoch: 47.878787878787875


2024-09-04 00:30:12,334 - INFO - Step: 110800
loss: 0.0002
grad_norm: 0.003407383104786277
learning_rate: 0.0004011544011544012
epoch: 47.96536796536797


2024-09-04 00:34:26,882 - INFO - Step: 110880
eval_loss: 0.0032115839421749115
eval_runtime: 191.4543
eval_samples_per_second: 496.385
eval_steps_per_second: 2.585
epoch: 48.0


2024-09-04 00:36:01,769 - INFO - Step: 111000
loss: 0.0002
grad_norm: 0.007367463782429695
learning_rate: 0.00039826839826839826
epoch: 48.05194805194805


2024-09-04 00:38:41,722 - INFO - Step: 111200
loss: 0.0002
grad_norm: 0.0047433567233383656
learning_rate: 0.0003953823953823954
epoch: 48.13852813852814


2024-09-04 00:41:20,594 - INFO - Step: 111400
loss: 0.0002
grad_norm: 0.001892570871859789
learning_rate: 0.00039249639249639253
epoch: 48.22510822510822


2024-09-04 00:44:00,235 - INFO - Step: 111600
loss: 0.0002
grad_norm: 0.002934701507911086
learning_rate: 0.00038961038961038966
epoch: 48.311688311688314


2024-09-04 00:46:38,798 - INFO - Step: 111800
loss: 0.0002
grad_norm: 0.0051002707332372665
learning_rate: 0.00038672438672438675
epoch: 48.3982683982684


2024-09-04 00:49:17,352 - INFO - Step: 112000
loss: 0.0002
grad_norm: 0.00390147534199059
learning_rate: 0.00038383838383838383
epoch: 48.484848484848484


2024-09-04 00:51:57,047 - INFO - Step: 112200
loss: 0.0002
grad_norm: 0.0005120969726704061
learning_rate: 0.00038095238095238096
epoch: 48.57142857142857


2024-09-04 00:54:35,598 - INFO - Step: 112400
loss: 0.0002
grad_norm: 0.0018823618302121758
learning_rate: 0.00037806637806637804
epoch: 48.65800865800866


2024-09-04 00:57:15,391 - INFO - Step: 112600
loss: 0.0002
grad_norm: 0.003944948315620422
learning_rate: 0.0003751803751803752
epoch: 48.74458874458875


2024-09-04 00:59:54,139 - INFO - Step: 112800
loss: 0.0002
grad_norm: 0.0022481440100818872
learning_rate: 0.0003722943722943723
epoch: 48.83116883116883


2024-09-04 01:02:32,812 - INFO - Step: 113000
loss: 0.0002
grad_norm: 0.0016037835739552975
learning_rate: 0.0003694083694083694
epoch: 48.917748917748916


2024-09-04 01:08:16,087 - INFO - Step: 113190
eval_loss: 0.0032769539393484592
eval_runtime: 191.2671
eval_samples_per_second: 496.871
eval_steps_per_second: 2.588
epoch: 49.0


2024-09-04 01:08:24,017 - INFO - Step: 113200
loss: 0.0002
grad_norm: 0.0030045900493860245
learning_rate: 0.00036652236652236653
epoch: 49.004329004329


2024-09-04 01:11:02,538 - INFO - Step: 113400
loss: 0.0002
grad_norm: 0.006110327783972025
learning_rate: 0.00036363636363636367
epoch: 49.09090909090909


2024-09-04 01:13:42,278 - INFO - Step: 113600
loss: 0.0002
grad_norm: 0.0027340103406459093
learning_rate: 0.00036075036075036075
epoch: 49.17748917748918


2024-09-04 01:16:20,632 - INFO - Step: 113800
loss: 0.0002
grad_norm: 0.001118547166697681
learning_rate: 0.0003578643578643579
epoch: 49.26406926406926


2024-09-04 01:18:58,509 - INFO - Step: 114000
loss: 0.0002
grad_norm: 0.0028903328347951174
learning_rate: 0.000354978354978355
epoch: 49.35064935064935


2024-09-04 01:21:38,263 - INFO - Step: 114200
loss: 0.0002
grad_norm: 0.0058286250568926334
learning_rate: 0.00035209235209235205
epoch: 49.43722943722944


2024-09-04 01:24:16,813 - INFO - Step: 114400
loss: 0.0002
grad_norm: 0.003319897223263979
learning_rate: 0.0003492063492063492
epoch: 49.523809523809526


2024-09-04 01:26:56,307 - INFO - Step: 114600
loss: 0.0002
grad_norm: 0.002281058579683304
learning_rate: 0.0003463203463203463
epoch: 49.61038961038961


2024-09-04 01:29:34,220 - INFO - Step: 114800
loss: 0.0002
grad_norm: 0.00475590443238616
learning_rate: 0.00034343434343434346
epoch: 49.696969696969695


2024-09-04 01:32:11,912 - INFO - Step: 115000
loss: 0.0002
grad_norm: 0.004037231672555208
learning_rate: 0.00034054834054834054
epoch: 49.78354978354978


2024-09-04 01:34:51,201 - INFO - Step: 115200
loss: 0.0002
grad_norm: 0.0011609751963987947
learning_rate: 0.00033766233766233767
epoch: 49.87012987012987


2024-09-04 01:37:29,302 - INFO - Step: 115400
loss: 0.0002
grad_norm: 0.0026033511385321617
learning_rate: 0.0003347763347763348
epoch: 49.95670995670996


2024-09-04 01:42:00,284 - INFO - Step: 115500
eval_loss: 0.003281729994341731
eval_runtime: 190.7115
eval_samples_per_second: 498.318
eval_steps_per_second: 2.596
epoch: 50.0


2024-09-04 01:43:19,106 - INFO - Step: 115600
loss: 0.0002
grad_norm: 0.005890781059861183
learning_rate: 0.0003318903318903319
epoch: 50.04329004329004


2024-09-04 01:45:57,559 - INFO - Step: 115800
loss: 0.0002
grad_norm: 0.0016395051497966051
learning_rate: 0.000329004329004329
epoch: 50.12987012987013


2024-09-04 01:48:36,280 - INFO - Step: 116000
loss: 0.0002
grad_norm: 0.003658914240077138
learning_rate: 0.00032611832611832616
epoch: 50.21645021645022


2024-09-04 01:51:15,848 - INFO - Step: 116200
loss: 0.0002
grad_norm: 0.0047891950234770775
learning_rate: 0.00032323232323232324
epoch: 50.303030303030305


2024-09-04 01:53:54,332 - INFO - Step: 116400
loss: 0.0002
grad_norm: 0.0023192856460809708
learning_rate: 0.0003203463203463203
epoch: 50.38961038961039


2024-09-04 01:56:34,295 - INFO - Step: 116600
loss: 0.0002
grad_norm: 0.005343024153262377
learning_rate: 0.00031746031746031746
epoch: 50.476190476190474


2024-09-04 01:59:12,987 - INFO - Step: 116800
loss: 0.0002
grad_norm: 0.001993185607716441
learning_rate: 0.00031457431457431454
epoch: 50.56277056277056


2024-09-04 02:01:51,467 - INFO - Step: 117000
loss: 0.0002
grad_norm: 0.0017244495684280992
learning_rate: 0.0003116883116883117
epoch: 50.64935064935065


2024-09-04 02:04:31,263 - INFO - Step: 117200
loss: 0.0002
grad_norm: 0.0060747722163796425
learning_rate: 0.0003088023088023088
epoch: 50.73593073593074


2024-09-04 02:07:09,799 - INFO - Step: 117400
loss: 0.0002
grad_norm: 0.004380397032946348
learning_rate: 0.00030591630591630595
epoch: 50.82251082251082


2024-09-04 02:09:49,469 - INFO - Step: 117600
loss: 0.0002
grad_norm: 0.0024517662823200226
learning_rate: 0.00030303030303030303
epoch: 50.90909090909091


2024-09-04 02:12:28,014 - INFO - Step: 117800
loss: 0.0002
grad_norm: 0.006375652272254229
learning_rate: 0.00030014430014430017
epoch: 50.995670995671


2024-09-04 02:15:46,469 - INFO - Step: 117810
eval_loss: 0.0034562847577035427
eval_runtime: 190.6458
eval_samples_per_second: 498.49
eval_steps_per_second: 2.596
epoch: 51.0


2024-09-04 02:18:17,081 - INFO - Step: 118000
loss: 0.0001
grad_norm: 0.0049241287633776665
learning_rate: 0.0002972582972582973
epoch: 51.082251082251084


2024-09-04 02:20:56,857 - INFO - Step: 118200
loss: 0.0001
grad_norm: 0.000786597141996026
learning_rate: 0.0002943722943722944
epoch: 51.16883116883117


2024-09-04 02:23:35,421 - INFO - Step: 118400
loss: 0.0002
grad_norm: 0.0035981680266559124
learning_rate: 0.00029148629148629146
epoch: 51.25541125541125


2024-09-04 02:26:14,344 - INFO - Step: 118600
loss: 0.0002
grad_norm: 0.0013004876673221588
learning_rate: 0.0002886002886002886
epoch: 51.34199134199134


2024-09-04 02:28:52,859 - INFO - Step: 118800
loss: 0.0002
grad_norm: 0.0010737889679148793
learning_rate: 0.0002857142857142857
epoch: 51.42857142857143


2024-09-04 02:31:30,948 - INFO - Step: 119000
loss: 0.0002
grad_norm: 0.001619068207219243
learning_rate: 0.0002828282828282828
epoch: 51.515151515151516


2024-09-04 02:34:09,924 - INFO - Step: 119200
loss: 0.0002
grad_norm: 0.0015655267052352428
learning_rate: 0.00027994227994227995
epoch: 51.6017316017316


2024-09-04 02:36:47,806 - INFO - Step: 119400
loss: 0.0002
grad_norm: 0.004384428728371859
learning_rate: 0.0002770562770562771
epoch: 51.688311688311686


2024-09-04 02:39:26,895 - INFO - Step: 119600
loss: 0.0002
grad_norm: 0.0015695719048380852
learning_rate: 0.00027417027417027417
epoch: 51.77489177489178


2024-09-04 02:42:04,607 - INFO - Step: 119800
loss: 0.0002
grad_norm: 0.004180085379630327
learning_rate: 0.0002712842712842713
epoch: 51.86147186147186


2024-09-04 02:44:42,840 - INFO - Step: 120000
loss: 0.0002
grad_norm: 0.0019968287087976933
learning_rate: 0.00026839826839826844
epoch: 51.94805194805195


2024-09-04 02:49:29,957 - INFO - Step: 120120
eval_loss: 0.0034744900185614824
eval_runtime: 191.0894
eval_samples_per_second: 497.333
eval_steps_per_second: 2.59
epoch: 52.0


2024-09-04 02:50:32,962 - INFO - Step: 120200
loss: 0.0002
grad_norm: 0.0012301780516281724
learning_rate: 0.0002655122655122655
epoch: 52.03463203463203


2024-09-04 02:53:12,014 - INFO - Step: 120400
loss: 0.0001
grad_norm: 0.000888326670974493
learning_rate: 0.00026262626262626266
epoch: 52.121212121212125


2024-09-04 02:55:51,637 - INFO - Step: 120600
loss: 0.0001
grad_norm: 0.002687983214855194
learning_rate: 0.00025974025974025974
epoch: 52.20779220779221


2024-09-04 02:58:30,641 - INFO - Step: 120800
loss: 0.0001
grad_norm: 0.0020554184447973967
learning_rate: 0.0002568542568542568
epoch: 52.294372294372295


2024-09-04 03:01:09,258 - INFO - Step: 121000
loss: 0.0001
grad_norm: 0.003401590511202812
learning_rate: 0.00025396825396825396
epoch: 52.38095238095238


2024-09-04 03:03:48,933 - INFO - Step: 121200
loss: 0.0001
grad_norm: 0.0014070527395233512
learning_rate: 0.0002510822510822511
epoch: 52.467532467532465


2024-09-04 03:06:27,150 - INFO - Step: 121400
loss: 0.0002
grad_norm: 0.0016016976442188025
learning_rate: 0.0002481962481962482
epoch: 52.55411255411256


2024-09-04 03:09:06,510 - INFO - Step: 121600
loss: 0.0002
grad_norm: 0.0011793896555900574
learning_rate: 0.0002453102453102453
epoch: 52.64069264069264


2024-09-04 03:11:44,833 - INFO - Step: 121800
loss: 0.0001
grad_norm: 0.005761162843555212
learning_rate: 0.00024242424242424245
epoch: 52.72727272727273


2024-09-04 03:14:23,183 - INFO - Step: 122000
loss: 0.0001
grad_norm: 0.00042843990377150476
learning_rate: 0.00023953823953823955
epoch: 52.81385281385281


2024-09-04 03:17:03,033 - INFO - Step: 122200
loss: 0.0001
grad_norm: 0.0005777440965175629
learning_rate: 0.00023665223665223664
epoch: 52.900432900432904


2024-09-04 03:19:41,983 - INFO - Step: 122400
loss: 0.0001
grad_norm: 0.001321392017416656
learning_rate: 0.00023376623376623377
epoch: 52.98701298701299


2024-09-04 03:23:16,995 - INFO - Step: 122430
eval_loss: 0.0038143417332321405
eval_runtime: 191.23
eval_samples_per_second: 496.967
eval_steps_per_second: 2.589
epoch: 53.0


2024-09-04 03:25:32,381 - INFO - Step: 122600
loss: 0.0001
grad_norm: 0.0017650664085522294
learning_rate: 0.00023088023088023088
epoch: 53.073593073593074


2024-09-04 03:28:11,532 - INFO - Step: 122800
loss: 0.0001
grad_norm: 0.003337196074426174
learning_rate: 0.00022799422799422802
epoch: 53.16017316017316


2024-09-04 03:30:50,567 - INFO - Step: 123000
loss: 0.0001
grad_norm: 0.005503255873918533
learning_rate: 0.00022510822510822512
epoch: 53.246753246753244


2024-09-04 03:33:30,539 - INFO - Step: 123200
loss: 0.0001
grad_norm: 0.002343890257179737
learning_rate: 0.0002222222222222222
epoch: 53.333333333333336


2024-09-04 03:36:09,431 - INFO - Step: 123400
loss: 0.0001
grad_norm: 0.0017878016224130988
learning_rate: 0.00021933621933621934
epoch: 53.41991341991342


2024-09-04 03:38:49,353 - INFO - Step: 123600
loss: 0.0001
grad_norm: 0.001144889509305358
learning_rate: 0.00021645021645021645
epoch: 53.506493506493506


2024-09-04 03:41:28,433 - INFO - Step: 123800
loss: 0.0001
grad_norm: 0.004708896391093731
learning_rate: 0.00021356421356421356
epoch: 53.59307359307359


2024-09-04 03:44:07,542 - INFO - Step: 124000
loss: 0.0001
grad_norm: 0.00216535828076303
learning_rate: 0.0002106782106782107
epoch: 53.67965367965368


2024-09-04 03:46:47,410 - INFO - Step: 124200
loss: 0.0001
grad_norm: 0.0033667245879769325
learning_rate: 0.0002077922077922078
epoch: 53.76623376623377


2024-09-04 03:49:26,439 - INFO - Step: 124400
loss: 0.0001
grad_norm: 0.000726793659850955
learning_rate: 0.0002049062049062049
epoch: 53.85281385281385


2024-09-04 03:52:06,317 - INFO - Step: 124600
loss: 0.0001
grad_norm: 0.002347787842154503
learning_rate: 0.00020202020202020202
epoch: 53.93939393939394


2024-09-04 03:57:07,953 - INFO - Step: 124740
eval_loss: 0.0035643859300762415
eval_runtime: 190.6055
eval_samples_per_second: 498.595
eval_steps_per_second: 2.597
epoch: 54.0


2024-09-04 03:57:55,202 - INFO - Step: 124800
loss: 0.0001
grad_norm: 0.005984446965157986
learning_rate: 0.00019913419913419913
epoch: 54.02597402597402


2024-09-04 04:00:34,545 - INFO - Step: 125000
loss: 0.0001
grad_norm: 0.0007456831517629325
learning_rate: 0.00019624819624819626
epoch: 54.112554112554115


2024-09-04 04:03:14,176 - INFO - Step: 125200
loss: 0.0001
grad_norm: 0.003035786096006632
learning_rate: 0.00019336219336219337
epoch: 54.1991341991342


2024-09-04 04:05:52,526 - INFO - Step: 125400
loss: 0.0001
grad_norm: 0.0030150047969073057
learning_rate: 0.00019047619047619048
epoch: 54.285714285714285


2024-09-04 04:08:32,181 - INFO - Step: 125600
loss: 0.0001
grad_norm: 0.0020206000190228224
learning_rate: 0.0001875901875901876
epoch: 54.37229437229437


2024-09-04 04:11:10,284 - INFO - Step: 125800
loss: 0.0001
grad_norm: 0.0015704084653407335
learning_rate: 0.0001847041847041847
epoch: 54.45887445887446


2024-09-04 04:13:48,759 - INFO - Step: 126000
loss: 0.0001
grad_norm: 0.0016091444995254278
learning_rate: 0.00018181818181818183
epoch: 54.54545454545455


2024-09-04 04:16:28,218 - INFO - Step: 126200
loss: 0.0001
grad_norm: 0.0014097068924456835
learning_rate: 0.00017893217893217894
epoch: 54.63203463203463


2024-09-04 04:19:07,129 - INFO - Step: 126400
loss: 0.0001
grad_norm: 0.001634561107493937
learning_rate: 0.00017604617604617602
epoch: 54.71861471861472


2024-09-04 04:21:46,087 - INFO - Step: 126600
loss: 0.0001
grad_norm: 0.0009378403192386031
learning_rate: 0.00017316017316017316
epoch: 54.8051948051948


2024-09-04 04:24:24,563 - INFO - Step: 126800
loss: 0.0001
grad_norm: 0.00151010078843683
learning_rate: 0.00017027417027417027
epoch: 54.891774891774894


2024-09-04 04:27:03,259 - INFO - Step: 127000
loss: 0.0001
grad_norm: 0.001721130800433457
learning_rate: 0.0001673881673881674
epoch: 54.97835497835498


2024-09-04 04:30:54,384 - INFO - Step: 127050
eval_loss: 0.003819715930148959
eval_runtime: 190.4949
eval_samples_per_second: 498.885
eval_steps_per_second: 2.598
epoch: 55.0


2024-09-04 04:32:52,956 - INFO - Step: 127200
loss: 0.0001
grad_norm: 0.001673559658229351
learning_rate: 0.0001645021645021645
epoch: 55.064935064935064


2024-09-04 04:35:31,859 - INFO - Step: 127400
loss: 0.0001
grad_norm: 0.0008074853685684502
learning_rate: 0.00016161616161616162
epoch: 55.15151515151515


2024-09-04 04:38:11,613 - INFO - Step: 127600
loss: 0.0001
grad_norm: 0.00279409671202302
learning_rate: 0.00015873015873015873
epoch: 55.23809523809524


2024-09-04 04:40:50,269 - INFO - Step: 127800
loss: 0.0001
grad_norm: 0.003127392614260316
learning_rate: 0.00015584415584415584
epoch: 55.324675324675326


2024-09-04 04:43:29,099 - INFO - Step: 128000
loss: 0.0001
grad_norm: 0.00033855304354801774
learning_rate: 0.00015295815295815297
epoch: 55.41125541125541


2024-09-04 04:46:08,921 - INFO - Step: 128200
loss: 0.0001
grad_norm: 0.0010354857658967376
learning_rate: 0.00015007215007215008
epoch: 55.497835497835496


2024-09-04 04:48:47,826 - INFO - Step: 128400
loss: 0.0001
grad_norm: 0.002403430873528123
learning_rate: 0.0001471861471861472
epoch: 55.58441558441559


2024-09-04 04:51:27,920 - INFO - Step: 128600
loss: 0.0001
grad_norm: 0.0019530865829437971
learning_rate: 0.0001443001443001443
epoch: 55.67099567099567


2024-09-04 04:54:07,144 - INFO - Step: 128800
loss: 0.0001
grad_norm: 0.0019406641367822886
learning_rate: 0.0001414141414141414
epoch: 55.75757575757576


2024-09-04 04:56:46,103 - INFO - Step: 129000
loss: 0.0001
grad_norm: 0.007635253947228193
learning_rate: 0.00013852813852813854
epoch: 55.84415584415584


2024-09-04 04:59:25,989 - INFO - Step: 129200
loss: 0.0001
grad_norm: 0.0007388198864646256
learning_rate: 0.00013564213564213565
epoch: 55.93073593073593


2024-09-04 05:04:43,011 - INFO - Step: 129360
eval_loss: 0.004067125264555216
eval_runtime: 190.2825
eval_samples_per_second: 499.442
eval_steps_per_second: 2.601
epoch: 56.0


2024-09-04 05:05:14,407 - INFO - Step: 129400
loss: 0.0001
grad_norm: 0.002734297653660178
learning_rate: 0.00013275613275613276
epoch: 56.01731601731602


2024-09-04 05:07:54,324 - INFO - Step: 129600
loss: 0.0001
grad_norm: 0.0010898127220571041
learning_rate: 0.00012987012987012987
epoch: 56.103896103896105


2024-09-04 05:10:33,253 - INFO - Step: 129800
loss: 0.0001
grad_norm: 0.0009148289100266993
learning_rate: 0.00012698412698412698
epoch: 56.19047619047619


2024-09-04 05:13:12,040 - INFO - Step: 130000
loss: 0.0001
grad_norm: 0.0009886932093650103
learning_rate: 0.0001240981240981241
epoch: 56.277056277056275


2024-09-04 05:15:51,851 - INFO - Step: 130200
loss: 0.0001
grad_norm: 0.0022589743603020906
learning_rate: 0.00012121212121212122
epoch: 56.36363636363637


2024-09-04 05:18:30,398 - INFO - Step: 130400
loss: 0.0001
grad_norm: 0.00019743904704228044
learning_rate: 0.00011832611832611832
epoch: 56.45021645021645


2024-09-04 05:21:10,050 - INFO - Step: 130600
loss: 0.0001
grad_norm: 0.0004496893670875579
learning_rate: 0.00011544011544011544
epoch: 56.53679653679654


2024-09-04 05:23:48,941 - INFO - Step: 130800
loss: 0.0001
grad_norm: 0.0013906455133110285
learning_rate: 0.00011255411255411256
epoch: 56.62337662337662


2024-09-04 05:26:27,748 - INFO - Step: 131000
loss: 0.0001
grad_norm: 0.0014779624762013555
learning_rate: 0.00010966810966810967
epoch: 56.70995670995671


2024-09-04 05:29:07,717 - INFO - Step: 131200
loss: 0.0001
grad_norm: 0.0014835039619356394
learning_rate: 0.00010678210678210678
epoch: 56.7965367965368


2024-09-04 05:31:46,705 - INFO - Step: 131400
loss: 0.0001
grad_norm: 0.004952439572662115
learning_rate: 0.0001038961038961039
epoch: 56.883116883116884


2024-09-04 05:34:26,518 - INFO - Step: 131600
loss: 0.0001
grad_norm: 0.001289467210881412
learning_rate: 0.00010101010101010101
epoch: 56.96969696969697


2024-09-04 05:38:32,698 - INFO - Step: 131670
eval_loss: 0.004283618181943893
eval_runtime: 190.6832
eval_samples_per_second: 498.392
eval_steps_per_second: 2.596
epoch: 57.0


2024-09-04 05:40:15,700 - INFO - Step: 131800
loss: 0.0001
grad_norm: 0.002649366157129407
learning_rate: 9.812409812409813e-05
epoch: 57.056277056277054


2024-09-04 05:42:54,891 - INFO - Step: 132000
loss: 0.0001
grad_norm: 0.0002938078250735998
learning_rate: 9.523809523809524e-05
epoch: 57.142857142857146


2024-09-04 05:45:34,682 - INFO - Step: 132200
loss: 0.0001
grad_norm: 0.0026009755674749613
learning_rate: 9.235209235209235e-05
epoch: 57.22943722943723


2024-09-04 05:48:13,496 - INFO - Step: 132400
loss: 0.0001
grad_norm: 0.004754065070301294
learning_rate: 8.946608946608947e-05
epoch: 57.316017316017316


2024-09-04 05:50:52,440 - INFO - Step: 132600
loss: 0.0001
grad_norm: 0.0007781394524499774
learning_rate: 8.658008658008658e-05
epoch: 57.4025974025974


2024-09-04 05:53:30,653 - INFO - Step: 132800
loss: 0.0001
grad_norm: 0.0005677168373949826
learning_rate: 8.36940836940837e-05
epoch: 57.489177489177486


2024-09-04 05:56:09,459 - INFO - Step: 133000
loss: 0.0001
grad_norm: 0.0025088470429182053
learning_rate: 8.080808080808081e-05
epoch: 57.57575757575758


2024-09-04 05:58:49,510 - INFO - Step: 133200
loss: 0.0001
grad_norm: 0.00226513110101223
learning_rate: 7.792207792207792e-05
epoch: 57.66233766233766


2024-09-04 06:01:28,267 - INFO - Step: 133400
loss: 0.0001
grad_norm: 0.0012755229836329818
learning_rate: 7.503607503607504e-05
epoch: 57.74891774891775


2024-09-04 06:04:07,883 - INFO - Step: 133600
loss: 0.0001
grad_norm: 0.0020404269453138113
learning_rate: 7.215007215007215e-05
epoch: 57.83549783549783


2024-09-04 06:06:46,395 - INFO - Step: 133800
loss: 0.0001
grad_norm: 0.0006825971649959683
learning_rate: 6.926406926406927e-05
epoch: 57.922077922077925


2024-09-04 06:12:19,712 - INFO - Step: 133980
eval_loss: 0.004452757071703672
eval_runtime: 190.5529
eval_samples_per_second: 498.733
eval_steps_per_second: 2.598
epoch: 58.0


2024-09-04 06:12:35,397 - INFO - Step: 134000
loss: 0.0001
grad_norm: 0.0023847282864153385
learning_rate: 6.637806637806638e-05
epoch: 58.00865800865801


2024-09-04 06:15:14,792 - INFO - Step: 134200
loss: 0.0001
grad_norm: 0.003975889645516872
learning_rate: 6.349206349206349e-05
epoch: 58.095238095238095


2024-09-04 06:17:53,234 - INFO - Step: 134400
loss: 0.0001
grad_norm: 0.0012705953558906913
learning_rate: 6.060606060606061e-05
epoch: 58.18181818181818


2024-09-04 06:20:32,674 - INFO - Step: 134600
loss: 0.0001
grad_norm: 0.00084634346421808
learning_rate: 5.772005772005772e-05
epoch: 58.26839826839827


2024-09-04 06:23:11,322 - INFO - Step: 134800
loss: 0.0001
grad_norm: 0.0006600407068617642
learning_rate: 5.4834054834054835e-05
epoch: 58.35497835497836


2024-09-04 06:25:49,496 - INFO - Step: 135000
loss: 0.0001
grad_norm: 0.0004601772816386074
learning_rate: 5.194805194805195e-05
epoch: 58.44155844155844


2024-09-04 06:28:28,792 - INFO - Step: 135200
loss: 0.0001
grad_norm: 0.001527245156466961
learning_rate: 4.9062049062049066e-05
epoch: 58.52813852813853


2024-09-04 06:31:07,713 - INFO - Step: 135400
loss: 0.0001
grad_norm: 0.00025204895064234734
learning_rate: 4.6176046176046175e-05
epoch: 58.61471861471861


2024-09-04 06:33:47,469 - INFO - Step: 135600
loss: 0.0001
grad_norm: 0.0005369610153138638
learning_rate: 4.329004329004329e-05
epoch: 58.701298701298704


2024-09-04 06:36:26,667 - INFO - Step: 135800
loss: 0.0001
grad_norm: 0.0011216740822419524
learning_rate: 4.0404040404040405e-05
epoch: 58.78787878787879


2024-09-04 06:39:05,420 - INFO - Step: 136000
loss: 0.0001
grad_norm: 0.001580730895511806
learning_rate: 3.751803751803752e-05
epoch: 58.874458874458874


2024-09-04 06:41:45,169 - INFO - Step: 136200
loss: 0.0001
grad_norm: 0.002151748165488243
learning_rate: 3.4632034632034636e-05
epoch: 58.96103896103896


2024-09-04 06:46:07,100 - INFO - Step: 136290
eval_loss: 0.004556519445031881
eval_runtime: 190.6352
eval_samples_per_second: 498.518
eval_steps_per_second: 2.597
epoch: 59.0


2024-09-04 06:47:34,260 - INFO - Step: 136400
loss: 0.0001
grad_norm: 0.0008571982034482062
learning_rate: 3.1746031746031745e-05
epoch: 59.04761904761905


2024-09-04 06:50:14,492 - INFO - Step: 136600
loss: 0.0001
grad_norm: 7.60293987696059e-05
learning_rate: 2.886002886002886e-05
epoch: 59.134199134199136


2024-09-04 06:52:53,446 - INFO - Step: 136800
loss: 0.0001
grad_norm: 0.002045207191258669
learning_rate: 2.5974025974025975e-05
epoch: 59.22077922077922


2024-09-04 06:55:32,389 - INFO - Step: 137000
loss: 0.0001
grad_norm: 0.0009179452899843454
learning_rate: 2.3088023088023087e-05
epoch: 59.307359307359306


2024-09-04 06:58:12,307 - INFO - Step: 137200
loss: 0.0001
grad_norm: 0.002026838483288884
learning_rate: 2.0202020202020203e-05
epoch: 59.39393939393939


2024-09-04 07:00:51,267 - INFO - Step: 137400
loss: 0.0001
grad_norm: 0.0008934825309552252
learning_rate: 1.7316017316017318e-05
epoch: 59.48051948051948


